{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data for next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create a .pkl file with the model's preditions and other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import load_config\n",
    "from dataloaders import *  \n",
    "from models import *       \n",
    "from uncertainty.MCDropout import MCDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "BATCH_SIZE = 64\n",
    "POSITIVE_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_FOLDER = 'UNIFESP+iCOPE'\n",
    "MODEL_NAME = 'NCNN_PRETRAINED'  # change model here\n",
    "BASE_EXPERIMENT_PATH = os.path.join('experiments', EXPERIMENTS_FOLDER, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCDP Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCDP SETTINGS\n",
    "MCDP = False\n",
    "MCDP_FOWARD_PASSES = 30\n",
    "MCDP_DROPOUT = 0.1 if \"NCNN\" in MODEL_NAME else 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hook(embeddings_list):\n",
    "    \"\"\"Return a hook function that appends flattened outputs to embeddings_list.\"\"\"\n",
    "    def hook(module, input, output):\n",
    "        output_np = output.detach().cpu().numpy()\n",
    "        for x in output_np:\n",
    "            embeddings_list.append(x.flatten())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(exp, mode, device, positive_threshold, batch_size):\n",
    "    \"\"\"\n",
    "    Process a single experiment directory.\n",
    "    \n",
    "    Parameters:\n",
    "        exp (str): Name of the experiment folder.\n",
    "        mode (str): Either 'train' or 'test'.\n",
    "        device (str): Device to run inference on.\n",
    "        positive_threshold (float): Threshold for positive predictions.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "        \n",
    "    Returns:\n",
    "        fold (str): Extracted fold name.\n",
    "        result (dict): Dictionary containing outputs and optionally embeddings.\n",
    "    \"\"\"\n",
    "    exp_path = os.path.join(BASE_EXPERIMENT_PATH, exp)\n",
    "    model_path = os.path.join(exp_path, 'Model', 'best_model.pt')\n",
    "    config_path = os.path.join(exp_path, 'Model', 'config.yaml')\n",
    "    \n",
    "    # Load configuration\n",
    "    config = load_config(config_path)\n",
    "    data_path = config['path_train'] if mode == 'train' else config['path_test']\n",
    "    \n",
    "    # Extract the fold from the data path (platform independent)\n",
    "    fold = os.path.normpath(data_path).split(os.sep)[-2]\n",
    "    print(f\"Processing {mode} data from: {data_path}\")\n",
    "    \n",
    "    # Set up embeddings collection and hook handle (if needed)\n",
    "    embeddings = []\n",
    "    hook_handle = None\n",
    "\n",
    "    # Choose model architecture and dataset based on experiment name\n",
    "    if \"NCNN\" in exp:\n",
    "        model_instance = NCNN()\n",
    "        dataset = NCNNDataset(data_path)\n",
    "        hook_handle = model_instance.fc_4.register_forward_hook(create_hook(embeddings))\n",
    "    elif \"VGGNB\" in exp:\n",
    "        model_instance = VGGNB()\n",
    "        dataset = VGGNBDataset(data_path)\n",
    "        # You may choose which layer to hook:\n",
    "        # hook_handle = model_instance.VGGFace.features.conv5_3.register_forward_hook(create_hook(embeddings))\n",
    "        hook_handle = model_instance.VGGFace.classifier[3].register_forward_hook(create_hook(embeddings))\n",
    "    elif \"ViTNB\" in exp:\n",
    "        model_instance = ViTNB()\n",
    "        dataset = ViTNBDataset(data_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown experiment type in {exp}\")\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Load model weights and prepare model for inference\n",
    "    model_instance.load_state_dict(torch.load(model_path))\n",
    "    model_instance = model_instance.to(device)\n",
    "    model_instance.eval()\n",
    "\n",
    "    # Accumulate outputs using lists (more efficient than repeated concatenation)\n",
    "    probs_list, preds_list, logits_list, labels_list = [], [], [], []\n",
    "\n",
    "    # If MCDP is activated, accumulate probabilities using a list\n",
    "    if MCDP:\n",
    "        probs_uq_list = []\n",
    "        model_instance = MCDropout(model_instance, p=MCDP_DROPOUT)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Processing {exp}\"):\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # If MCDP calculate probabilities for each forward pass\n",
    "            if MCDP:\n",
    "                probs = model_instance.predict(inputs, reps=MCDP_FOWARD_PASSES)\n",
    "                preds = torch.ge(torch.mean(probs, dim=1), positive_threshold).type(torch.int)\n",
    "                probs_uq_list.append(probs)\n",
    "\n",
    "            else:\n",
    "                logits = model_instance(inputs)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                preds = (probs >= positive_threshold).int()\n",
    "                logits_list.append(logits)\n",
    "\n",
    "            probs_list.append(probs)\n",
    "            preds_list.append(preds)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    # Concatenate tensors and convert to numpy arrays\n",
    "    probs_all = torch.cat(probs_list).cpu().numpy()\n",
    "    preds_all = torch.cat(preds_list).cpu().numpy()\n",
    "    labels_all = torch.cat(labels_list).cpu().numpy()\n",
    "\n",
    "    if MCDP:\n",
    "        probs_uq_all = torch.cat(probs_uq_list).cpu().numpy()\n",
    "\n",
    "        result = {\n",
    "            'img_names': np.array(dataset.img_names),\n",
    "            'probs': probs_all,\n",
    "            'preds': preds_all,\n",
    "            'labels': labels_all,\n",
    "            'probs_uq': probs_uq_all\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        logits_all = torch.cat(logits_list).cpu().numpy()\n",
    "        \n",
    "        result = {\n",
    "            'img_names': np.array(dataset.img_names),\n",
    "            'probs': probs_all,\n",
    "            'preds': preds_all,\n",
    "            'logits': logits_all,\n",
    "            'labels': labels_all,\n",
    "            'embeddings': np.array(embeddings)\n",
    "        }\n",
    "\n",
    "    # Remove hook if it was set\n",
    "    if hook_handle is not None:\n",
    "        hook_handle.remove()\n",
    "\n",
    "    # Cleanup GPU memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return fold, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main loop to process all experiments for each mode and save results.\"\"\"\n",
    "    modes = ['train', 'test']\n",
    "\n",
    "    if MCDP:\n",
    "        save_filenames = [f'train_results_MCDP_{MCDP_DROPOUT}_{MCDP_FOWARD_PASSES}.pkl', \n",
    "                          f'results_MCDP_{MCDP_DROPOUT}_{MCDP_FOWARD_PASSES}.pkl']\n",
    "    else:\n",
    "        save_filenames = ['train_results.pkl', 'results.pkl']\n",
    "\n",
    "    for mode, save_filename in zip(modes, save_filenames):\n",
    "        results = {}\n",
    "        # List all experiment directories in the base experiments path\n",
    "        for exp in os.listdir(BASE_EXPERIMENT_PATH):\n",
    "            # Filter out non-experiment files\n",
    "            if any(sub in exp for sub in ['.pkl', 'masks', '.png']):\n",
    "                continue\n",
    "            try:\n",
    "                fold, res = process_experiment(exp, mode, DEVICE, POSITIVE_THRESHOLD, BATCH_SIZE)\n",
    "                results[fold] = res\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {exp}: {e}\")\n",
    "\n",
    "        output_path = os.path.join(BASE_EXPERIMENT_PATH, save_filename)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        print(f\"Saved {mode} results to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\0\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0902_NCNN: 100%|██████████| 151/151 [00:14<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\1\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0905_NCNN: 100%|██████████| 155/155 [00:14<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\2\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0908_NCNN: 100%|██████████| 152/152 [00:14<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\3\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0912_NCNN: 100%|██████████| 154/154 [00:14<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\4\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0914_NCNN: 100%|██████████| 155/155 [00:14<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\5\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0919_NCNN: 100%|██████████| 152/152 [00:13<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\6\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0922_NCNN: 100%|██████████| 151/151 [00:13<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\7\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0928_NCNN: 100%|██████████| 154/154 [00:13<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\8\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0931_NCNN: 100%|██████████| 160/160 [00:13<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train data from: Datasets\\Folds\\9\\Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0935_NCNN: 100%|██████████| 159/159 [00:13<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train results to experiments\\UNIFESP+iCOPE\\NCNN_PRETRAINED\\train_results.pkl\n",
      "Processing test data from: Datasets\\Folds\\0\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0902_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\1\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0905_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\2\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0908_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\3\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0912_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\4\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0914_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\5\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0919_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\6\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0922_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\7\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0928_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\8\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0931_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data from: Datasets\\Folds\\9\\Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 20250222_0935_NCNN: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test results to experiments\\UNIFESP+iCOPE\\NCNN_PRETRAINED\\results.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-hoc Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_FOLDER = 'UNIFESP+iCOPE'\n",
    "MODEL_NAME = 'NCNN_PRETRAINED'  # change model here\n",
    "BASE_EXPERIMENT_PATH = os.path.join('experiments', EXPERIMENTS_FOLDER, MODEL_NAME)\n",
    "\n",
    "filename = 'results_MCDP_0.5_30.pkl'  # change here\n",
    "filename_calib = 'train_results_MCDP_0.5_30.pkl'  # change here\n",
    "\n",
    "positive_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_post_hoc(results, calib_results, calibrator):\n",
    "\n",
    "    for fold in results.keys():\n",
    "        calibrator.fit(calib_results[fold]['probs'], calib_results[fold]['labels'])\n",
    "        calibrated_probs = calibrator.predict(results[fold]['probs'])\n",
    "\n",
    "        results[fold]['probs'] = calibrated_probs\n",
    "        results[fold]['preds'] = (calibrated_probs >= positive_threshold).astype('float32')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_mcdp(results, calib_results, calibrator):\n",
    "\n",
    "    for fold in results.keys():\n",
    "\n",
    "        calibrator.fit(calib_results[fold]['probs'], calib_results[fold]['labels'])\n",
    "        \n",
    "        if calibrator.__class__.__name__ == \"IsotonicRegressor\":\n",
    "            calibrated_probs = np.empty_like(results[fold]['probs_uq'])\n",
    "            for i, x in enumerate(results[fold]['probs_uq']):\n",
    "                calibrated_probs[i] = calibrator.predict(x)\n",
    "        else:\n",
    "            calibrated_probs = calibrator.predict(results[fold]['probs_uq'])\n",
    "\n",
    "        results[fold]['probs_uq'] = calibrated_probs\n",
    "        results[fold]['probs'] = calibrated_probs.mean(axis=1)\n",
    "        results[fold]['preds'] = (calibrated_probs.mean(axis=1) >= positive_threshold).astype('float32')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platt Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename_calib), 'rb') as f:\n",
    "    calib_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration.calibrators import PlattScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platt = PlattScaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdp = \"MCDP_\" if \"MCDP\" in filename else \"\"\n",
    "save_filename = f'results_{mcdp}PLATT.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = calibrate_post_hoc(results=results, calib_results=calib_results, calibrator=platt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, save_filename), 'wb') as f:\n",
    "    pickle.dump(new_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename_calib), 'rb') as f:\n",
    "    calib_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration.calibrators import TemperatureScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = TemperatureScaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdp = \"MCDP_\" if \"MCDP\" in filename else \"\"\n",
    "save_filename = f'results_{mcdp}TEMPERATURE.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = calibrate_post_hoc(results=results, calib_results=calib_results, calibrator=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, save_filename), 'wb') as f:\n",
    "    pickle.dump(new_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotonic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename_calib), 'rb') as f:\n",
    "    calib_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration.calibrators import IsotonicRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsotonicRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdp = \"MCDP_\" if \"MCDP\" in filename else \"\"\n",
    "save_filename = f'results_{mcdp}ISOTONIC.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = calibrate_post_hoc(results=results, calib_results=calib_results, calibrator=iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, save_filename), 'wb') as f:\n",
    "    pickle.dump(new_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(BASE_EXPERIMENT_PATH, filename_calib), 'rb') as f:\n",
    "    calib_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration.calibrators import HistogramBinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bin = HistogramBinning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdp = \"MCDP_\" if \"MCDP\" in filename else \"\"\n",
    "save_filename = f'results_{mcdp}HIST.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = calibrate_post_hoc(results=results, calib_results=calib_results, calibrator=hist_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_EXPERIMENT_PATH, save_filename), 'wb') as f:\n",
    "    pickle.dump(new_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
