{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create a classification and calibration metrics reports with values and graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from validate import validation_metrics, calibration_metrics\n",
    "from utils.plots import probability_histogram\n",
    "from calibration.metrics import ECE, calibration_curve\n",
    "\n",
    "plt.style.use('utils/plotstyle.mplstyle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_pad_average_arrays(arrays):\n",
    "    \"\"\"\n",
    "    Given a list of 1D arrays of potentially different lengths, pad them with NaNs\n",
    "    and compute the average and standard deviation at each index, ignoring NaNs.\n",
    "    \"\"\"\n",
    "    max_length = max(len(arr) for arr in arrays)\n",
    "    # Pad each array with NaNs to the maximum length.\n",
    "    padded = [np.pad(arr, (0, max_length - len(arr)), constant_values=np.nan) for arr in arrays]\n",
    "    padded = np.vstack(padded)\n",
    "    avg = np.nanmean(padded, axis=0)\n",
    "    std = np.nanstd(padded, axis=0)\n",
    "    return avg, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results, path_experiments):\n",
    "    # Compute validation metrics for each fold.\n",
    "\n",
    "    unique_folds = results['fold'].unique()\n",
    "\n",
    "    val_metrics = [validation_metrics(results[results['fold'] == fold]['preds'], results[results['fold'] == fold]['probs'], results[results['fold'] == fold]['labels'])\n",
    "                   for fold in unique_folds]\n",
    "\n",
    "    \n",
    "    accuracy    = np.array([m['Accuracy']    for m in val_metrics])\n",
    "    f1          = np.array([m['F1 Score']    for m in val_metrics])\n",
    "    precision   = np.array([m['Precision']   for m in val_metrics])\n",
    "    sensitivity = np.array([m['Sensitivity'] for m in val_metrics])\n",
    "    specificity = np.array([m['Specificity'] for m in val_metrics])\n",
    "    auc         = np.array([m['AUC']         for m in val_metrics])\n",
    "    \n",
    "    # Compute calibration metrics for each fold.\n",
    "    n_bins = 10\n",
    "    mode_metrics = 'quantile'\n",
    "    mode_plot    = 'uniform'\n",
    "    \n",
    "    calib_metrics = [calibration_metrics(results[results['fold'] == fold]['probs'], results[results['fold'] == fold]['labels'],\n",
    "                                         n_bins=n_bins, mode=mode_metrics)\n",
    "                     for fold in unique_folds]\n",
    "    \n",
    "    ece    = np.array([m['ECE']    for m in calib_metrics])\n",
    "    mce    = np.array([m['MCE']    for m in calib_metrics])\n",
    "    nll    = np.array([m['NLL']    for m in calib_metrics])\n",
    "    brier  = np.array([m['Brier']  for m in calib_metrics])\n",
    "    \n",
    "    # Build a string summary using join (replacing dots with commas)\n",
    "    metrics_arrays = [accuracy, f1, precision, sensitivity, specificity, auc, ece, mce, nll, brier]\n",
    "    lines = [\n",
    "        \";\".join(str(np.round(val, 4)).replace('.', ',') for val in arr)\n",
    "        for arr in metrics_arrays\n",
    "    ]\n",
    "    summary_str = \"\\n\".join(lines)\n",
    "    print(summary_str)\n",
    "\n",
    "    \"\"\"\n",
    "    prob_true, prob_pred, _ = calibration_curve(results['probs'], results['labels'], n_bins=n_bins, mode=mode_plot)\n",
    "    # Create figure with a single gridspec call.\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=(3, 1),\n",
    "                          left=0.1, right=0.9, bottom=0.1, top=0.9, hspace=0.05)\n",
    "    ax_curve = fig.add_subplot(gs[0])\n",
    "    ax_hist  = fig.add_subplot(gs[1])\n",
    "    \n",
    "    # Plot calibration curve.\n",
    "    ax_curve.plot(np.arange(0, 1.1, 0.1), np.arange(0, 1.1, 0.1),\n",
    "                  linestyle=\":\", color='#9e9e9e')\n",
    "    ax_curve.plot(prob_pred, prob_true, marker='o',\n",
    "                  label=f'ECE = {ece.mean():.4f} ± {ece.std():.2f}')\n",
    "\n",
    "    # Plot histogram of predicted probabilities.\n",
    "    ax_hist.hist(results['probs'], bins=np.linspace(0.0, 1.0, n_bins + 1),\n",
    "                 edgecolor='black')\n",
    "    \n",
    "    ax_curve.set_ylabel('Fração de Positivos')\n",
    "    ax_curve.legend(loc='upper left')\n",
    "    ax_curve.set_ylim([0, 1.01])\n",
    "    ax_curve.set_xlim([0, 1.01])\n",
    "    ax_curve.set_xticklabels([])\n",
    "    \n",
    "    ax_hist.set_xlabel('Probabilidade Prevista Média')\n",
    "    ax_hist.set_ylabel('Quantidade')\n",
    "    ax_hist.set_xlim([0, 1])\n",
    "    \n",
    "    plt.savefig(os.path.join(path_experiments, \"calib_curve.pdf\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute calibration curves for each fold.\n",
    "    list_prob_true, list_prob_pred, list_probs, ece_list = [], [], [], []\n",
    "    for fold in unique_folds:\n",
    "        prob_true, prob_pred, _ = calibration_curve(results[results['fold'] == fold]['probs'], results[results['fold'] == fold]['labels'],\n",
    "                                                    n_bins=n_bins, mode=mode_plot)\n",
    "        list_prob_true.append(prob_true)\n",
    "        list_prob_pred.append(prob_pred)\n",
    "        list_probs.extend(results[results['fold'] == fold]['probs'])\n",
    "        ece_list.append(ECE(results[results['fold'] == fold]['probs'], results[results['fold'] == fold]['labels'],\n",
    "                            n_bins=n_bins, mode=mode_metrics))\n",
    "    \n",
    "    average_prob_true, std_prob = calib_pad_average_arrays(list_prob_true)\n",
    "    average_prob_pred, std_pred = calib_pad_average_arrays(list_prob_pred)\n",
    "    list_probs = np.array(list_probs)\n",
    "    average_ece = np.mean(ece_list)\n",
    "    std_ece = np.std(ece_list)\n",
    "    \n",
    "    # Create figure with a single gridspec call.\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=(3, 1),\n",
    "                          left=0.1, right=0.9, bottom=0.1, top=0.9, hspace=0.05)\n",
    "    ax_curve = fig.add_subplot(gs[0])\n",
    "    ax_hist  = fig.add_subplot(gs[1], sharex=ax_curve)\n",
    "    \n",
    "    # Plot calibration curve.\n",
    "    ax_curve.plot(np.arange(0, 1.1, 0.1), np.arange(0, 1.1, 0.1),\n",
    "                  linestyle=\":\", color='#9e9e9e')\n",
    "    ax_curve.plot(average_prob_pred, average_prob_true, marker='o',\n",
    "                  label=f'ECE = {average_ece:.4f} ± {std_ece:.2f}')\n",
    "    ax_curve.fill_between(average_prob_pred, np.clip(average_prob_true-std_prob,0,1),np.clip(average_prob_true+std_prob,0,1), alpha=0.3, edgecolor='None')\n",
    "\n",
    "    # Plot histogram of predicted probabilities.\n",
    "    ax_hist.hist(list_probs, bins=np.linspace(0.0, 1.0, n_bins + 1),\n",
    "                 edgecolor='black')\n",
    "    \n",
    "    ax_curve.set_ylabel('Fração de Positivos')\n",
    "    ax_curve.legend(loc='upper left')\n",
    "    ax_curve.set_ylim([0, 1])\n",
    "    ax_curve.set_xlim([0, 1])\n",
    "    ax_curve.tick_params(labelbottom=False)\n",
    "    \n",
    "    \n",
    "    ax_hist.set_xlabel('Probabilidade Prevista Média')\n",
    "    ax_hist.set_ylabel('Quantidade')\n",
    "    ax_hist.set_xlim([0, 1])\n",
    "    \n",
    "    plt.savefig(os.path.join(path_experiments, \"calib_curve.pdf\"))\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrator: \n",
      "0,8491\n",
      "0,8182\n",
      "0,9\n",
      "0,75\n",
      "0,931\n",
      "0,8477\n",
      "0,0712\n",
      "0,1915\n",
      "0,4301\n",
      "0,1347\n",
      "calibrator: _HIST\n",
      "calibrator: _ISOTONIC\n",
      "calibrator: _LINEAR\n",
      "calibrator: _LS_01\n",
      "calibrator: _LS_03\n",
      "calibrator: _LS_05\n",
      "calibrator: _PLATT\n",
      "calibrator: _SIGMOID\n",
      "calibrator: _STEP\n",
      "calibrator: _TEMP\n"
     ]
    }
   ],
   "source": [
    "#calibrators = [\"\", \"_LS_01\", \"_LS_03\", \"_LS_05\", \"_SIGMOID\", \"_LINEAR\", \"_STEP\", \"_PLATT\" , \"_ISOTONIC\", \"_TEMP\",\"_HIST\"]\n",
    "calibrators = [\"\", \"_HIST\", \"_ISOTONIC\", \"_LINEAR\", \"_LS_01\", \"_LS_03\", \"_LS_05\", \"_PLATT\", \"_SIGMOID\", \"_STEP\", \"_TEMP\"]\n",
    "\n",
    "\n",
    "folder = \"\"\n",
    "model = 'NCNN_FINAL'  # change model here\n",
    "model_results_file = 'results.pkl'\n",
    "\n",
    "for calibrator in calibrators:\n",
    "    print(f\"calibrator: {calibrator}\")\n",
    "    path_experiments = os.path.join('experiments', folder, f\"{model}{calibrator}\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(path_experiments, model_results_file), 'rb') as f:\n",
    "            daata = pickle.load(f)\n",
    "            daata.pop('embeddings', None)  # Remove embeddings if present\n",
    "            results = pd.DataFrame(daata)\n",
    "    \n",
    "        show_results(results, path_experiments)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "labels = []\n",
    "for fold in results.keys():\n",
    "    probs.extend(results[fold]['probs'])\n",
    "    labels.extend(results[fold]['labels'])\n",
    "\n",
    "probability_histogram(np.array(probs), np.array(labels), path=path_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doutorado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
