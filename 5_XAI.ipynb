{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import create_folder, load_config\n",
    "from dataloaders.presets import PresetTransform\n",
    "from dataloaders import *  \n",
    "from models import *\n",
    "from XAI import *\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI CLASSIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "folder = ''\n",
    "model = 'ViT_B_32_ENSEMBLE\\\\ensemble_9'\n",
    "\n",
    "path_experiments = f'experiments\\\\{folder}\\\\{model}'\n",
    "path_masks = os.path.join(path_experiments, 'xai_masks')\n",
    "path_mean_XAI = os.path.join(path_experiments, 'xai_masks', 'mean_masks')\n",
    "\n",
    "path_mesh = 'Datasets\\\\DatasetFaces\\\\Landmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results.pkl'\n",
    "\n",
    "with open(os.path.join(path_experiments,filename), 'rb') as f:\n",
    "    daata = pickle.load(f)\n",
    "    daata.pop('embeddings', None)  # Remove embeddings if present\n",
    "    dataframe = pd.DataFrame(daata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(path_masks)\n",
    "create_folder(path_mean_XAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your batch size (adjust based on your memory/GPU capacity)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for exp in os.listdir(path_experiments):\n",
    "    # Skip non-experiment folders/files.\n",
    "    if any(ext in exp for ext in ['.pkl', 'masks', '.png', '.pdf']):\n",
    "        continue\n",
    "\n",
    "    # Load model and configuration.\n",
    "    path_model = os.path.join(path_experiments, exp, 'Model', 'best_model.pt')\n",
    "    path_yaml  = os.path.join(path_experiments, exp, 'Model', 'config.yaml')\n",
    "    config     = load_config(path_yaml)\n",
    "    test_path  = config['path_test']\n",
    "\n",
    "    # Set up the model, transforms, and attribution objects based on experiment type.\n",
    "    if \"NCNN\" in exp:\n",
    "        model = NCNN().to(device)\n",
    "        img_size = 120\n",
    "        transform = PresetTransform(\"NCNN\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.merge_branch[0], device=device)\n",
    "    elif \"VGGFace\" in exp:\n",
    "        model = VGGFace().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"VGGFace\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.VGGFace.features.conv5_3, device=device)\n",
    "    elif \"ViT\" in exp:\n",
    "        model = ViT().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"ViT\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model,\n",
    "                          model.ViT.encoder.layers.encoder_layer_11.ln_1,\n",
    "                          device=device,\n",
    "                          reshape_transform_ViT=True)\n",
    "    elif \"PainClassifier\" in exp:\n",
    "        model = PainClassifier().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"PainClassifier\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.arcface_model.vgg.features[28], device=device)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Load the trained weights and set the model to evaluation mode.\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model.eval()\n",
    "\n",
    "    # Get list of test images.\n",
    "    image_files = [f for f in os.listdir(test_path) if f.endswith('.jpg')]\n",
    "\n",
    "    # Process images in batches.\n",
    "    for batch_start in tqdm(range(0, len(image_files), BATCH_SIZE)):\n",
    "        batch_files = image_files[batch_start: batch_start + BATCH_SIZE]\n",
    "        transformed_list = []   # List of transformed tensors for the batch.\n",
    "        rgb_list         = []   # List of RGB images (for plotting).\n",
    "        img_names        = []   # List of metadata tuples: (img_name).\n",
    "\n",
    "        for img_file in batch_files:\n",
    "            full_img_path = os.path.join(test_path, img_file)\n",
    "\n",
    "            img_rgb = Image.open(os.path.join(full_img_path)).convert(\"RGB\")\n",
    "            img_rgb = img_rgb.resize((img_size, img_size))\n",
    "            \n",
    "            img_name = img_file.split(\".jpg\")[0]\n",
    "            # Extract label from the filename.\n",
    "            label = 1 if img_file.split(\".jpg\")[0].split(\"_\")[3] == 'pain' else 0\n",
    "\n",
    "            if \"VGGFace\" in exp:\n",
    "                img_input = Image.fromarray(np.array(img_rgb)[:, :, ::-1])\n",
    "            else:\n",
    "                img_input = img_rgb\n",
    "\n",
    "            # Normalize the image.\n",
    "            #img_input = img_input / 255.0\n",
    "            #img_input = np.float32(img_input)\n",
    "\n",
    "            # Apply the transform.\n",
    "            transformed = transform(img_input)\n",
    "            transformed_list.append(transformed)\n",
    "            rgb_list.append(img_rgb)\n",
    "            img_names.append(img_name)\n",
    "\n",
    "        # Stack the batch of images: shape becomes (B, C, H, W).\n",
    "        batch_tensor = torch.stack(transformed_list, dim=0).to(device)\n",
    "\n",
    "        # Compute the attribution masks in batch.\n",
    "        masks_ig = ig.attribution_mask(batch_tensor)   # Expected shape: (B, H, W)\n",
    "        masks_gc = gradcam.attribution_mask(batch_tensor)  # Expected shape: (B, H, W)\n",
    "\n",
    "        # Loop over each image in the batch to post-process, save, and plot.\n",
    "        for i in range(len(batch_files)):\n",
    "            mask_ig_i = masks_ig[i]\n",
    "            mask_gc_i = masks_gc[i]\n",
    "\n",
    "            # Save the attribution masks as pickle files.\n",
    "            ig_pkl_name   = f\"{img_names[i]}_IG.pkl\"\n",
    "            gc_pkl_name   = f\"{img_names[i]}_GC.pkl\"\n",
    "\n",
    "            with open(os.path.join(path_masks, ig_pkl_name), 'wb') as f:\n",
    "                pickle.dump(mask_ig_i, f)\n",
    "            with open(os.path.join(path_masks, gc_pkl_name), 'wb') as f:\n",
    "                pickle.dump(mask_gc_i, f)\n",
    "\n",
    "            # Apply post-processing to get results for plotting.\n",
    "            result_ig, alpha_channel_ig = attribution_mask_processing(mask_ig_i, use_mini_batch=False)\n",
    "            result_gc, alpha_channel_gc = attribution_mask_processing(mask_gc_i, use_mini_batch=False)\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\", \"yellow\", \"red\"])\n",
    "\n",
    "            # Plot and save the Integrated Gradients overlay.\n",
    "            #ig_png_name = ig_pkl_name.replace('.pkl', '.png')\n",
    "            #plt.figure(figsize=(8, 8))\n",
    "            #plt.imshow(rgb_list[i])\n",
    "            #plt.imshow(result_ig, cmap=cmap, alpha=alpha_channel_ig)\n",
    "            #plt.axis('off')\n",
    "            #plt.savefig(os.path.join(path_masks, ig_png_name), dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "            #plt.close()\n",
    "\n",
    "            # Plot and save the GradCAM overlay.\n",
    "            #gc_png_name = gc_pkl_name.replace('.pkl', '.png')\n",
    "            #plt.figure(figsize=(8, 8))\n",
    "            #plt.imshow(rgb_list[i])\n",
    "            #plt.imshow(result_gc, cmap=cmap, alpha=alpha_channel_gc)\n",
    "            #plt.axis('off')\n",
    "            #plt.savefig(os.path.join(path_masks, gc_png_name), dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "            #plt.close()\n",
    "\n",
    "    # Cleanup after processing each experiment.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI ENSEMBLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_uint8(m): return (np.clip(m, 0, 1)*255).round().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1042 unique mask filenames to average.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1042 [00:00<?, ?it/s]  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "100%|██████████| 1042/1042 [13:56<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch import mode\n",
    "\n",
    "# --- Config ---\n",
    "device = 'cuda'\n",
    "folder = ''  # e.g., 'run_42' — leave '' if already correct\n",
    "model = 'ViT_B_32_ENSEMBLE'\n",
    "\n",
    "# --- Paths ---\n",
    "path_experiments = os.path.join('experiments', folder, model)\n",
    "path_masks_root = os.path.join(path_experiments, 'xai_masks')\n",
    "path_mean_XAI = os.path.join(path_masks_root, 'mean_masks')\n",
    "\n",
    "def create_folder(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "create_folder(path_masks_root)\n",
    "create_folder(path_mean_XAI)\n",
    "\n",
    "# --- Gather all pkl files across ensembles, grouped by filename ---\n",
    "files_by_name = {}\n",
    "for i in range(10):  # ensemble_0 .. ensemble_9\n",
    "    ensemble_mask_dir = os.path.join(path_experiments, f'ensemble_{i}', 'xai_masks')\n",
    "    if not os.path.isdir(ensemble_mask_dir):\n",
    "        print(f'[skip] {ensemble_mask_dir} (not found)')\n",
    "        continue\n",
    "\n",
    "    for pkl_path in glob.glob(os.path.join(ensemble_mask_dir, '*.npz')):\n",
    "        fname = os.path.basename(pkl_path)\n",
    "        files_by_name.setdefault(fname, []).append(pkl_path)\n",
    "\n",
    "if not files_by_name:\n",
    "    raise RuntimeError('No .npz heatmaps found under any ensemble_i/xai_masks/ directory.')\n",
    "\n",
    "print(f'Found {len(files_by_name)} unique mask filenames to average.')\n",
    "\n",
    "if \"VGG\" in model:\n",
    "    img_size = 224\n",
    "elif \"ViT\" in model:\n",
    "    img_size = 224\n",
    "elif \"NCNN\" in model:\n",
    "    img_size = 120    \n",
    "\n",
    "# --- Average per filename across ensembles ---\n",
    "for fname, paths in tqdm(files_by_name.items()):\n",
    "    arrays = []\n",
    "    shape_ref = None\n",
    "\n",
    "    for p in paths:\n",
    "        arr = np.load(p)['mask'] / 255\n",
    "\n",
    "        if not isinstance(arr, np.ndarray):\n",
    "            raise TypeError(f'{p} does not contain a NumPy array.')\n",
    "\n",
    "        if shape_ref is None:\n",
    "            shape_ref = arr.shape\n",
    "        elif arr.shape != shape_ref:\n",
    "            raise ValueError(f'Shape mismatch for {fname}: {arr.shape} vs {shape_ref} (file: {p})')\n",
    "\n",
    "        arrays.append(arr.astype(np.float32, copy=False))\n",
    "\n",
    "    if len(arrays) == 0:\n",
    "        print(f'[warn] No arrays loaded for {fname}, skipping.')\n",
    "        continue\n",
    "\n",
    "    mean_arr = np.mean(np.stack(arrays, axis=0), axis=0)  # [N, H, W] -> [H, W]\n",
    "    std_arr = np.std(np.stack(arrays, axis=0), axis=0)  # [N, H, W] -> [H, W]\n",
    "\n",
    "    std_norm = (std_arr - std_arr.min()) / (std_arr.ptp() + 1e-8)\n",
    "    xai_norm_adjusted = mean_arr * (1 - std_norm)\n",
    "\n",
    "    save_path = os.path.join(path_masks_root, fname)\n",
    "\n",
    "    out = to_uint8(xai_norm_adjusted)\n",
    "    np.savez_compressed(save_path, mask=out)\n",
    "    \n",
    "    # Apply post-processing to get results for plotting.\n",
    "    result, alpha_channel = attribution_mask_processing(xai_norm_adjusted, use_mini_batch=False)\n",
    "    \n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\", \"yellow\", \"red\"])\n",
    "\n",
    "    full_img_path = \"Datasets\\\\DatasetFaces\\\\Images\\\\\" + fname.rsplit(\"_\", 1)[0]+\".jpg\"\n",
    "\n",
    "    img_rgb = Image.open(os.path.join(full_img_path)).convert(\"RGB\")\n",
    "    img_rgb = img_rgb.resize((img_size, img_size))\n",
    "\n",
    "    # Plot and save the Integrated Gradients overlay.\n",
    "    png_name = fname.replace('.npz', '.png')\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.imshow(result, cmap=cmap, alpha=alpha_channel)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(path_masks_root, png_name), dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI MCDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_uint8(m): return (np.clip(m, 0, 1)*255).round().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "folder = ''\n",
    "model = 'NCNN'\n",
    "\n",
    "path_experiments = f'experiments\\\\{folder}\\\\{model}'\n",
    "path_masks = os.path.join(path_experiments, 'xai_masks_MCDP')\n",
    "path_mean_XAI = os.path.join(path_experiments, 'xai_masks_MCDP', 'mean_masks')\n",
    "\n",
    "path_mesh = 'Datasets\\\\DatasetFaces\\\\Landmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results_MCDP_50_0.3.pkl'\n",
    "\n",
    "with open(os.path.join(path_experiments,filename), 'rb') as f:\n",
    "    daata = pickle.load(f)\n",
    "    daata.pop('embeddings', None)  # Remove embeddings if present\n",
    "    dataframe = pd.DataFrame(daata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(path_masks)\n",
    "create_folder(path_mean_XAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def enable_mc_dropout(model: nn.Module, p: float = 0.1):\n",
    "    \"\"\"\n",
    "    Put only Dropout layers in train mode and set their p.\n",
    "    Keep everything else in eval. Useful after model.eval().\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.p = p\n",
    "            m.train()\n",
    "\n",
    "def welford_update(mean, m2, x, k):\n",
    "    # x, mean, m2 are np arrays with same shape\n",
    "    if mean is None:\n",
    "        mean = x.astype(np.float32)\n",
    "        m2   = np.zeros_like(mean, dtype=np.float32)\n",
    "    else:\n",
    "        delta  = x - mean\n",
    "        mean  += delta / k\n",
    "        m2    += delta * (x - mean)\n",
    "    return mean, m2\n",
    "\n",
    "def welford_finalize(mean, m2, n, unbiased=False):\n",
    "    denom = (n - 1) if unbiased and n > 1 else n\n",
    "    std = np.sqrt(m2 / denom)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\leona\\anaconda3\\envs\\doutorado\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "100%|██████████| 2/2 [00:55<00:00, 27.53s/it]\n",
      "100%|██████████| 2/2 [00:51<00:00, 25.54s/it]\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.09s/it]\n",
      "100%|██████████| 2/2 [01:00<00:00, 30.18s/it]\n",
      "100%|██████████| 2/2 [01:02<00:00, 31.37s/it]\n",
      "100%|██████████| 2/2 [01:07<00:00, 33.65s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your batch size (adjust based on your memory/GPU capacity)\n",
    "BATCH_SIZE = 32\n",
    "MC_SAMPLES   = 50            # how many forward passes\n",
    "DROPOUT_P    = 0.3           # dropout prob to use at test time\n",
    "UNBIASED_STD = False         # use population std (False) or sample std (True)\n",
    "\n",
    "\n",
    "for exp in os.listdir(path_experiments):\n",
    "    # Skip non-experiment folders/files.\n",
    "    if any(ext in exp for ext in ['.pkl', 'masks', '.png', '.pdf']):\n",
    "        continue\n",
    "\n",
    "    # Load model and configuration.\n",
    "    path_model = os.path.join(path_experiments, exp, 'Model', 'best_model.pt')\n",
    "    path_yaml  = os.path.join(path_experiments, exp, 'Model', 'config.yaml')\n",
    "    config     = load_config(path_yaml)\n",
    "    test_path  = config['path_test']\n",
    "\n",
    "    # Set up the model, transforms, and attribution objects based on experiment type.\n",
    "    if \"NCNN\" in exp:\n",
    "        model = NCNN().to(device)\n",
    "        img_size = 120\n",
    "        transform = PresetTransform(\"NCNN\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.merge_branch[0], device=device)\n",
    "    elif \"VGGFace\" in exp:\n",
    "        model = VGGFace().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"VGGFace\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.VGGFace.features.conv5_3, device=device)\n",
    "    elif \"ViT\" in exp:\n",
    "        model = ViT().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"ViT\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model,\n",
    "                          model.ViT.encoder.layers.encoder_layer_11.ln_1,\n",
    "                          device=device,\n",
    "                          reshape_transform_ViT=True)\n",
    "    elif \"PainClassifier\" in exp:\n",
    "        model = PainClassifier().to(device)\n",
    "        img_size = 224\n",
    "        transform = PresetTransform(\"PainClassifier\").transforms\n",
    "        ig      = IntegratedGradients(model, device=device)\n",
    "        gradcam = GradCAM(model, model.arcface_model.vgg.features[28], device=device)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Load the trained weights and set the model to evaluation mode.\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model.eval()\n",
    "    enable_mc_dropout(model, DROPOUT_P)\n",
    "\n",
    "    # Get list of test images.\n",
    "    image_files = [f for f in os.listdir(test_path) if f.endswith('.jpg')]\n",
    "\n",
    "    # Process images in batches.\n",
    "    for batch_start in tqdm(range(0, len(image_files), BATCH_SIZE)):\n",
    "        batch_files = image_files[batch_start: batch_start + BATCH_SIZE]\n",
    "        transformed_list = []   # List of transformed tensors for the batch.\n",
    "        rgb_list         = []   # List of RGB images (for plotting).\n",
    "        img_names        = []   # List of metadata tuples: (img_name).\n",
    "\n",
    "        for img_file in batch_files:\n",
    "            full_img_path = os.path.join(test_path, img_file)\n",
    "\n",
    "            img_rgb = Image.open(os.path.join(full_img_path)).convert(\"RGB\")\n",
    "            img_rgb = img_rgb.resize((img_size, img_size))\n",
    "            \n",
    "            img_name = img_file.split(\".jpg\")[0]\n",
    "            # Extract label from the filename.\n",
    "            label = 1 if img_file.split(\".jpg\")[0].split(\"_\")[3] == 'pain' else 0\n",
    "\n",
    "            if \"VGGFace\" in exp:\n",
    "                img_input = Image.fromarray(np.array(img_rgb)[:, :, ::-1])\n",
    "            else:\n",
    "                img_input = img_rgb\n",
    "\n",
    "            # Normalize the image.\n",
    "            #img_input = img_input / 255.0\n",
    "            #img_input = np.float32(img_input)\n",
    "\n",
    "            # Apply the transform.\n",
    "            transformed = transform(img_input)\n",
    "            transformed_list.append(transformed)\n",
    "            rgb_list.append(img_rgb)\n",
    "            img_names.append(img_name)\n",
    "\n",
    "        # Stack the batch of images: shape becomes (B, C, H, W).\n",
    "        batch_tensor = torch.stack(transformed_list, dim=0).to(device)\n",
    "\n",
    "        ig_mean = ig_m2 = gc_mean = gc_m2 = None\n",
    "        for k in range(1, MC_SAMPLES + 1):\n",
    "            masks_ig_k = ig.attribution_mask(batch_tensor)      # np.ndarray (B,H,W)\n",
    "            masks_gc_k = gradcam.attribution_mask(batch_tensor) # np.ndarray (B,H,W)\n",
    "\n",
    "            ig_mean, ig_m2 = welford_update(ig_mean, ig_m2, masks_ig_k, k)\n",
    "            gc_mean, gc_m2 = welford_update(gc_mean, gc_m2, masks_gc_k, k)\n",
    "\n",
    "        masks_ig_mean, masks_ig_std = welford_finalize(ig_mean, ig_m2, MC_SAMPLES, UNBIASED_STD)\n",
    "        masks_gc_mean, masks_gc_std = welford_finalize(gc_mean, gc_m2, MC_SAMPLES, UNBIASED_STD)\n",
    "\n",
    "        # Loop over each image in the batch to post-process, save, and plot.\n",
    "        for i in range(len(batch_files)):\n",
    "            ig_mean_i = masks_ig_mean[i]\n",
    "            gc_mean_i = masks_gc_mean[i]\n",
    "            ig_std_i  = masks_ig_std[i]\n",
    "            gc_std_i  = masks_gc_std[i]\n",
    "\n",
    "            # Names\n",
    "            base_name = img_names[i]\n",
    "            ig_mean_pkl = f\"{base_name}_IG.npz\"\n",
    "            gc_mean_pkl = f\"{base_name}_GC.npz\"\n",
    "\n",
    "            gc_std_norm = (gc_std_i - gc_std_i.min()) / (gc_std_i.ptp() + 1e-8)\n",
    "            gc_norm_adjusted = gc_mean_i * (1 - gc_std_norm)\n",
    "            out_gc = to_uint8(gc_norm_adjusted)\n",
    "            np.savez_compressed(os.path.join(path_masks, gc_mean_pkl), mask=out_gc)\n",
    "\n",
    "            ig_std_norm = (ig_std_i - ig_std_i.min()) / (ig_std_i.ptp() + 1e-8)\n",
    "            ig_norm_adjusted = ig_mean_i * (1 - ig_std_norm)\n",
    "            out_ig = to_uint8(ig_norm_adjusted)\n",
    "            np.savez_compressed(os.path.join(path_masks, ig_mean_pkl), mask=out_ig)\n",
    "         \n",
    "\n",
    "            # Plot overlays for means as before\n",
    "            result_ig, alpha_ig = attribution_mask_processing(gc_norm_adjusted, use_mini_batch=False)\n",
    "            result_gc, alpha_gc = attribution_mask_processing(ig_norm_adjusted, use_mini_batch=False)\n",
    "\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\", \"yellow\", \"red\"])\n",
    "\n",
    "            # IG mean\n",
    "            ig_png_name = f\"{base_name}_IG.png\"\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(rgb_list[i])\n",
    "            plt.imshow(result_ig, cmap=cmap, alpha=alpha_ig)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(path_masks, ig_png_name), dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            # GC mean\n",
    "            gc_png_name = f\"{base_name}_GC.png\"\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(rgb_list[i])\n",
    "            plt.imshow(result_gc, cmap=cmap, alpha=alpha_gc)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(path_masks, gc_png_name), dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "    # Cleanup after processing each experiment.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from XAI.metrics import create_face_regions_masks, calculate_xai_score\n",
    "from XAI import attribution_mask_processing\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.style.use('utils\\plotstyle.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mesh = 'Datasets\\\\DatasetFaces\\\\Landmarks'\n",
    "\n",
    "model = 'NCNN'\n",
    "path_xai = f'experiments\\\\{model}\\\\xai_masks'\n",
    "path_results = f'experiments\\\\{model}\\\\results.pkl'\n",
    "\n",
    "with open(path_results, 'rb') as f:\n",
    "    daata = pickle.load(f)\n",
    "    daata.pop('embeddings', None)  # Remove embeddings if present\n",
    "    dataframe = pd.DataFrame(daata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_symmetric_masks(face_masks):\n",
    "    # Define symmetric region mappings: (left_key, right_key) → new_key\n",
    "    merge_map = {\n",
    "        ('left_eye', 'right_eye'): 'eyes',\n",
    "        ('left_cheek', 'right_cheek'): 'cheeks',\n",
    "        ('left_eyebrown', 'right_eyebrown'): 'eyebrowns',\n",
    "        ('left_nasolabial_fold', 'right_nasolabial_fold'): 'nasolabial_folds',\n",
    "    }\n",
    "\n",
    "    new_masks = {}\n",
    "    used_keys = set()\n",
    "\n",
    "    # Merge symmetric pairs\n",
    "    for (left, right), new_key in merge_map.items():\n",
    "        if left in face_masks and right in face_masks:\n",
    "            new_masks[new_key] = np.logical_or(face_masks[left], face_masks[right]).astype(np.uint8)\n",
    "            used_keys.update([left, right])\n",
    "\n",
    "    # Keep all other regions that are not merged\n",
    "    for key, mask in face_masks.items():\n",
    "        if key not in used_keys:\n",
    "            new_masks[key] = mask\n",
    "\n",
    "    return new_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'TP': dataframe[(dataframe['preds'] == dataframe['labels']) & (dataframe['preds'] == 1)],\n",
    "    'TN': dataframe[(dataframe['preds'] == dataframe['labels']) & (dataframe['preds'] == 0)],\n",
    "    'FP': dataframe[(dataframe['preds'] != dataframe['labels']) & (dataframe['preds'] == 1)],\n",
    "    'FN': dataframe[(dataframe['preds'] != dataframe['labels']) & (dataframe['preds'] == 0)],\n",
    "}\n",
    "\n",
    "#groups = {\n",
    "#    'Dor': dataframe[dataframe['preds'] == 1],\n",
    "#    'Sem Dor': dataframe[dataframe['preds'] == 0],\n",
    "#}\n",
    "\n",
    "xai_methods = ['GC', 'IG']\n",
    "xai_raw = []\n",
    "\n",
    "for XAI_method in xai_methods:\n",
    "    for group_name, df in groups.items():\n",
    "        for _, row in df.iterrows():\n",
    "            file_name = row['img_names']\n",
    "            base_name = file_name.split('\\\\')[-1].split('.')[0]\n",
    "            file_name_mesh = base_name + '.pkl'\n",
    "            file_name_xai = base_name + f'_{XAI_method}.pkl'\n",
    "\n",
    "            try:\n",
    "                with open(os.path.join(path_mesh, file_name_mesh), 'rb') as f:\n",
    "                    mesh = np.array(pickle.load(f))\n",
    "                with open(os.path.join(path_xai, file_name_xai), 'rb') as f:\n",
    "                    xai = np.array(pickle.load(f))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            if xai.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            masks = create_face_regions_masks(mesh)\n",
    "            masks = merge_symmetric_masks(masks)\n",
    "            xai_processed, alpha_xai = attribution_mask_processing(cv2.resize(xai, (512, 512)))\n",
    "            xai_processed = xai_processed * alpha_xai  # Apply alpha channel to the processed mask\n",
    "            xai_score = calculate_xai_score(xai_processed, masks, sort=True)\n",
    "\n",
    "            for region, score in xai_score.items():\n",
    "                xai_raw.append({\n",
    "                    'Image': file_name,\n",
    "                    'Group': group_name,\n",
    "                    'Region': region,\n",
    "                    'Score': score,\n",
    "                    'XAI_Method': XAI_method  # Add method info\n",
    "                })\n",
    "\n",
    "# Final DataFrame\n",
    "xai_df = pd.DataFrame(xai_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduções dos grupos\n",
    "group_translation = {\n",
    "    'TP': 'Verdadeiro Positivo',\n",
    "    'TN': 'Verdadeiro Negativo',\n",
    "    'FP': 'Falso Positivo',\n",
    "    'FN': 'Falso Negativo'\n",
    "}\n",
    "\n",
    "#group_translation = {\n",
    "#    'Sem Dor': 'Sem dor',\n",
    "#    'Dor': 'Com dor',\n",
    "#}\n",
    "\n",
    "# Traduções das regiões faciais\n",
    "region_translation = {\n",
    "    'outside': 'Fora do rosto',\n",
    "    'chin': 'Queixo',\n",
    "    'mouth': 'Boca',\n",
    "    'nasolabial_folds': 'Sulco nasolabiais',\n",
    "    'cheeks': 'Bochechas',\n",
    "    'nose': 'Nariz',\n",
    "    'eyebrowns': 'Sobrancelhas',\n",
    "    'eyes': 'Olhos',\n",
    "    'between_eyes': 'Entre os olhos',\n",
    "    'forehead': 'Testa'\n",
    "}\n",
    "\n",
    "# Aplicar traduções no DataFrame\n",
    "xai_df['Grupo'] = xai_df['Group'].map(group_translation)\n",
    "xai_df['Região'] = xai_df['Region'].map(region_translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_df[xai_df[\"Image\"]==r\"Datasets\\Folds\\0\\Test\\ID169_iCOPE_S15_pain.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Convert Score to float (if needed, since you have commas)\n",
    "xai_df[\"Score\"] = xai_df[\"Score\"].astype(str).str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# 2) Get the row with the maximum score per (Image, Group, XAI_Method)\n",
    "idx = xai_df.groupby([\"Image\", \"Group\", \"XAI_Method\"])[\"Score\"].idxmax()\n",
    "top_regions = xai_df.loc[idx]\n",
    "\n",
    "# 3) Count how many times each region appears as the top one\n",
    "counts = (\n",
    "    top_regions.groupby([\"XAI_Method\", \"Group\", \"Region\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    "    .sort_values([\"XAI_Method\", \"Group\", \"Count\"], ascending=[True, True, False])\n",
    ")\n",
    "\n",
    "print(counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Translate region names if needed\n",
    "xai_df['Região'] = xai_df['Region'].map(region_translation)\n",
    "\n",
    "# Step 2: Order regions by overall median score\n",
    "region_order_pt = ([\"Boca\",\t\"Bochechas\",\t\"Entre os olhos\",\t\"Fora do rosto\"\t,\"Nariz\",\t\"Olhos\"\t,\"Queixo\"\t,\"Sobrancelhas\"\t,\"Sulco nasolabiais\",\t\"Testa\"])\n",
    "\n",
    "# Step 3: Create subplots\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(15, 10), sharex=True)\n",
    "\n",
    "for ax, method in zip(axes, ['GC', 'IG']):\n",
    "    subset = xai_df[xai_df['XAI_Method'] == method]\n",
    "\n",
    "    # Plot boxplot\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x='Região',\n",
    "        y='Score',\n",
    "        hue='Grupo',\n",
    "        order=region_order_pt,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # Compute per-group ranks\n",
    "    #medians_dor = (\n",
    "    #    subset[subset['Grupo'] == 'Dor']\n",
    "    #    .groupby('Região')['Score']\n",
    "    #    .mean()\n",
    "    #    .sort_values(ascending=False)\n",
    "    #    .rank(ascending=False, method='min')\n",
    "    #    .astype(int)\n",
    "    #    .to_dict()\n",
    "    #)\n",
    "    #medians_sem_dor = (\n",
    "    #    subset[subset['Grupo'] == 'Sem Dor']\n",
    "    #    .groupby('Região')['Score']\n",
    "    #    .mean()\n",
    "    #    .sort_values(ascending=False)\n",
    "    #    .rank(ascending=False, method='min')\n",
    "    #    .astype(int)\n",
    "    #    .to_dict()\n",
    "    #)\n",
    "\n",
    "    # Add annotation for each box (offset each group slightly)\n",
    "    for i, region in enumerate(region_order_pt):\n",
    "        y_max_dor = subset[(subset['Região'] == region) & (subset['Grupo'] == 'Dor')]['Score'].median()\n",
    "        y_max_sem_dor = subset[(subset['Região'] == region) & (subset['Grupo'] == 'Sem Dor')]['Score'].median()\n",
    "\n",
    "\n",
    "        # Dor (left)\n",
    "       # if region in medians_dor:\n",
    "       #     rank = medians_dor[region]\n",
    "       #     color = '#2ECC71' if rank <= 3 else 'lightgray'\n",
    "       #     ax.text(\n",
    "       #         i - 0.2, y_max_dor, f\"{rank}\",\n",
    "       #         ha='center', va='bottom',\n",
    "       #         fontsize=9, fontweight='bold', color='black',\n",
    "       #         bbox=dict(facecolor=color, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "       #     )\n",
    "\n",
    "        # Sem Dor (right)\n",
    "       # if region in medians_sem_dor:\n",
    "       #     rank = medians_sem_dor[region]\n",
    "       #     color = '#2ECC71' if rank <= 3 else 'lightgray'\n",
    "       #     ax.text(\n",
    "       #         i + 0.2, y_max_sem_dor, f\"{rank}\",\n",
    "       #         ha='center', va='bottom',\n",
    "       #         fontsize=9, fontweight='bold', color='black',\n",
    "       #         bbox=dict(facecolor=color, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "       #     )\n",
    "\n",
    "    ax.set_title('Grad-CAM' if method == 'GC' else 'Integrated Gradients')\n",
    "    ax.set_ylabel('Pontuação de Importância')\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    if method == 'IG':\n",
    "        ax.legend(title='Tipo de Predição', loc='upper right')\n",
    "    else:\n",
    "        ax.legend_.remove()\n",
    "\n",
    "# Final layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path_xai, 'xai_distribution_ranked.pdf'), dpi=300, bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Translate region names\n",
    "xai_df['Região'] = xai_df['Region'].map(region_translation)\n",
    "\n",
    "# Group by Region, Group, and XAI_Method → mean and std\n",
    "summary = (\n",
    "    xai_df\n",
    "    .groupby(['Group', 'XAI_Method', 'Região'])['Score']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary['ScoreFormatted'] = summary.apply(\n",
    "    lambda row: f\"{row['mean']:.4f} ± {row['std']:.4f}\".replace(\".\", \",\"), axis=1\n",
    ")\n",
    "\n",
    "# Pivot: rows = Group + XAI_Method, columns = Região\n",
    "table = summary.pivot_table(\n",
    "    index=['XAI_Method', 'Group'],\n",
    "    columns='Região',\n",
    "    values='ScoreFormatted',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optional: order columns for presentation\n",
    "cols = ['Group', 'XAI_Method'] + sorted([col for col in table.columns if col not in ['Group', 'XAI_Method']])\n",
    "table = table[cols]\n",
    "\n",
    "# Display\n",
    "table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate mean score per group-method-region\n",
    "grouped = (\n",
    "    xai_df\n",
    "    .groupby(['Group', 'XAI_Method', 'Região'])['Score']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 2: Rank and filter top-3 per group-method\n",
    "grouped['Rank'] = grouped.groupby(['Group', 'XAI_Method'])['Score'].rank(ascending=False, method='first')\n",
    "top3 = grouped[grouped['Rank'] <= 10].copy()\n",
    "\n",
    "# Step 3: Sort properly for display\n",
    "top3 = top3.sort_values(['XAI_Method','Group', 'Rank'])\n",
    "\n",
    "# Step 4: Pivot to a nice table format\n",
    "top3['Rank'] = top3['Rank'].astype(int)\n",
    "top3_formatted = top3.pivot_table(\n",
    "    index=['XAI_Method', 'Group'],\n",
    "    columns='Rank',\n",
    "    values='Região',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Optional: Rename columns\n",
    "top3_formatted.columns.name = None\n",
    "top3_formatted.rename(columns={1: 'Top 1', 2: 'Top 2', 3: 'Top 3', 4: 'Top 4', 5: 'Top 5', 6: 'Top 6', 7: 'Top 7', 8: 'Top 8', 9: 'Top 9', 10: 'Top 10'}, inplace=True)\n",
    "\n",
    "top3_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calculate_region_rank_correlation(importance_dict1, importance_dict2):\n",
    "    \"\"\"\n",
    "    Calculates Spearman's rank correlation coefficient between two dictionaries of importance scores by region.\n",
    "\n",
    "    Args:\n",
    "    importance_dict1 (dict): Dictionary of region importance scores from the first method.\n",
    "    importance_dict2 (dict): Dictionary of region importance scores from the second method.\n",
    "\n",
    "    Returns:\n",
    "    float: Spearman's rank correlation coefficient between -1 and 1.\n",
    "    \"\"\"\n",
    "    # Get the regions common to both importance dictionaries\n",
    "    common_regions = set(importance_dict1.keys()).intersection(importance_dict2.keys())\n",
    "\n",
    "    # Extract the importance scores for these common regions in the same order for both dictionaries\n",
    "    scores1 = [importance_dict1[region] for region in common_regions]\n",
    "    scores2 = [importance_dict2[region] for region in common_regions]\n",
    "\n",
    "    # Calculate Spearman's rank correlation coefficient\n",
    "    correlation, _ = spearmanr(scores1, scores2)\n",
    "\n",
    "    return correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_region_rank_agreement(importance_dict1, importance_dict2, k, return_agreed_set=False):\n",
    "    \"\"\"\n",
    "    Calculates the rank-based agreement between two dictionaries of importance scores by region.\n",
    "\n",
    "    Args:\n",
    "    importance_dict1 (dict): Dictionary of region importance scores from the first method.\n",
    "    importance_dict2 (dict): Dictionary of region importance scores from the second method.\n",
    "    k (int): Number of top regions to consider.\n",
    "    return_agreed_set (bool): Whether to return the set of agreed regions in matching ranks.\n",
    "\n",
    "    Returns:\n",
    "    float: Agreement score between 0 and 1, representing the fraction of matching top-k regions by rank.\n",
    "    list (optional): List of agreed regions in matching ranks if return_agreed_set is True.\n",
    "    \"\"\"\n",
    "    # Sort each dictionary by importance and get the ordered top k regions as lists\n",
    "    top_k_regions_1 = sorted(importance_dict1, key=importance_dict1.get, reverse=True)[:k]\n",
    "    top_k_regions_2 = sorted(importance_dict2, key=importance_dict2.get, reverse=True)[:k]\n",
    "\n",
    "    # Calculate matching regions in the same rank positions\n",
    "    agreed_regions = [region1 for region1, region2 in zip(top_k_regions_1, top_k_regions_2) if region1 == region2]\n",
    "\n",
    "    # Calculate the agreement score based on matching positions\n",
    "    agreement_score = len(agreed_regions) / k\n",
    "\n",
    "    if return_agreed_set:\n",
    "        return agreement_score, agreed_regions\n",
    "    else:\n",
    "        return agreement_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_region_agreement(importance_dict1, importance_dict2, k, return_agreed_set=False):\n",
    "    \"\"\"\n",
    "    Calculates the agreement between two dictionaries of importance scores by region.\n",
    "\n",
    "    Args:\n",
    "    importance_dict1 (dict): Dictionary of region importance scores from the first method.\n",
    "    importance_dict2 (dict): Dictionary of region importance scores from the second method.\n",
    "    k (int): Number of top regions to consider.\n",
    "    return_agreed_set (bool): Whether to return the set of agreed regions in the result.\n",
    "\n",
    "    Returns:\n",
    "    float: Agreement score between 0 and 1, representing the fraction of shared top-k regions.\n",
    "    set (optional): Set of agreed regions if return_agreed_set is True.\n",
    "    \"\"\"\n",
    "    # Sort each dictionary by importance and get the top k regions\n",
    "    top_k_regions_1 = set(sorted(importance_dict1, key=importance_dict1.get, reverse=True)[:k])\n",
    "    top_k_regions_2 = set(sorted(importance_dict2, key=importance_dict2.get, reverse=True)[:k])\n",
    "\n",
    "    # Calculate the intersection of the top k regions\n",
    "    agreed_regions = top_k_regions_1.intersection(top_k_regions_2)\n",
    "\n",
    "    # Calculate the agreement score\n",
    "    agreement_score = len(agreed_regions) / k\n",
    "\n",
    "    if return_agreed_set:\n",
    "        return agreement_score, agreed_regions\n",
    "    else:\n",
    "        return agreement_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduções dos grupos\n",
    "group_translation = {\n",
    "    'TP': 'Verdadeiro Positivo',\n",
    "    'TN': 'Verdadeiro Negativo',\n",
    "    'FP': 'Falso Positivo',\n",
    "    'FN': 'Falso Negativo'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = lambda x: f\"{x:,.4f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "\n",
    "\n",
    "# Step 1: Create all group-method combinations\n",
    "all_scores = {}\n",
    "\n",
    "for method in ['GC', 'IG']:\n",
    "    for group in ['Verdadeiro Positivo', \"Verdadeiro Negativo\", \"Falso Positivo\", \"Falso Negativo\"]:\n",
    "        subset = xai_df[(xai_df['Grupo'] == group) & (xai_df['XAI_Method'] == method)]\n",
    "        region_scores = (\n",
    "            subset[['Região', 'Score']]\n",
    "            .groupby('Região')\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .set_index('Região')['Score']\n",
    "            .to_dict()\n",
    "        )\n",
    "        # Sort descending by score\n",
    "        region_scores = dict(sorted(region_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        all_scores[f\"{group}_{method}\"] = region_scores\n",
    "\n",
    "results = []\n",
    "\n",
    "for (name1, dict1), (name2, dict2) in combinations(all_scores.items(), 2):\n",
    "    rank_corr = calculate_region_rank_correlation(dict1, dict2)\n",
    "\n",
    "    rank_agreement_score, rank_agreed_set = calculate_region_rank_agreement(dict1, dict2, k=3, return_agreed_set=True)\n",
    "    agreement_score, agreed_set = calculate_region_agreement(dict1, dict2, k=3, return_agreed_set=True)\n",
    "\n",
    "    row = {\n",
    "        'Model_1': name1,\n",
    "        'Model_2': name2,\n",
    "        'RankCorrelation': rank_corr,\n",
    "        'RankAgreement@3': rank_agreement_score,\n",
    "        'Agreement@3': agreement_score,\n",
    "        'RankAgreedRegions@3': ', '.join(sorted(rank_agreed_set)),\n",
    "        'AgreedRegions@3': ', '.join(sorted(agreed_set))\n",
    "    }\n",
    "    results.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[\"XAI_Comparison\"] = (\n",
    "    comparison_df[\"Model_1\"].str.strip().str.extract(r'_(GC|IG)$')[0] + \" x \" +\n",
    "    comparison_df[\"Model_2\"].str.strip().str.extract(r'_(GC|IG)$')[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df[\"XAI_Comparison\"] == \"GC x GC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- util: construir matriz simétrica a partir de pares (Model_1, Model_2) ---\n",
    "def build_matrix(df, metric: str):\n",
    "    labels = sorted(set(df[\"Model_1\"]).union(set(df[\"Model_2\"])))\n",
    "    idx = {lab: i for i, lab in enumerate(labels)}\n",
    "    n = len(labels)\n",
    "    mat = np.full((n, n), np.nan, dtype=float)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        i, j = idx[row[\"Model_1\"]], idx[row[\"Model_2\"]]\n",
    "        val = float(str(row[metric]).replace(\",\", \".\"))  # handle numbers with comma\n",
    "        mat[i, j] = val\n",
    "        mat[j, i] = val\n",
    "\n",
    "    np.fill_diagonal(mat, 1.0)\n",
    "    return mat, labels\n",
    "\n",
    "def plot_heatmap(matrix, labels, title, outfile):\n",
    "    fig, ax = plt.subplots(figsize=(0.55*len(labels)+4, 0.55*len(labels)+4), dpi=120)\n",
    "    im = ax.imshow(matrix, interpolation=\"nearest\")\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, len(labels), 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, len(labels), 1), minor=True)\n",
    "    ax.grid(which=\"minor\", linestyle=\"-\", linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel(\"Score\", rotation=90, va=\"center\")\n",
    "\n",
    "    # annotate\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            v = matrix[i, j]\n",
    "            ax.text(j, i, \"\" if np.isnan(v) else f\"{v:.2f}\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    os.makedirs(\"heatmaps\", exist_ok=True)\n",
    "    fig.savefig(outfile, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {outfile}\")\n",
    "\n",
    "# --- metrics to plot ---\n",
    "metrics = [\n",
    "    (\"RankCorrelation\", \"Rank Correlation (ρ)\"),\n",
    "    (\"RankAgreement@3\", \"Rank Agreement@3\"),\n",
    "    (\"Agreement@3\",     \"Agreement@3\"),\n",
    "]\n",
    "\n",
    "# --- loop over each slice of XAI_Comparison ---\n",
    "for method_pair, slice_df in comparison_df.groupby(\"XAI_Comparison\"):\n",
    "    for metric, title in metrics:\n",
    "        mat, labs = build_matrix(slice_df, metric)\n",
    "        fname = f\"heatmaps/{method_pair.replace(' ', '_')}_{metric}.png\"\n",
    "        plot_heatmap(mat, labs, f\"{title} – {method_pair}\", fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = []\n",
    "for i in os.listdir(path_mesh):\n",
    "    with open(os.path.join(path_mesh,f'{i}'), 'rb') as f:\n",
    "        face_mesh = np.array(pickle.load(f))\n",
    "\n",
    "    faces.append(face_mesh)\n",
    "\n",
    "faces_np = np.array(faces)\n",
    "face_mesh_mean = faces_np.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = merge_symmetric_masks(create_face_regions_masks(face_mesh_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xai_df[xai_df['Group'] == 'TP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['Region', 'Score']].groupby('Region').mean().reset_index()\n",
    "test['Região'] = test['Region'].map(region_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def draw_face_colormap(region_scores, region_masks, title='', cmap='coolwarm', show_top_n=3):\n",
    "    h, w = next(iter(region_masks.values())).shape\n",
    "    heatmap = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    values = region_scores['Score'].values\n",
    "    min_val, max_val = values.min(), values.max()\n",
    "\n",
    "    for region, mask in region_masks.items():\n",
    "        score = region_scores[region_scores['Region'] == region]['Score'].values[0]\n",
    "        normalized_score = (score - min_val) / (max_val - min_val + 1e-8)\n",
    "        heatmap = np.maximum(heatmap, mask * normalized_score)\n",
    "\n",
    "    # Get top-N regions by original (non-normalized) score\n",
    "    top_features = (\n",
    "        region_scores.sort_values(by='Score', ascending=False)\n",
    "        .head(show_top_n)\n",
    "        .apply(lambda row: f\"{row['Região']}\", axis=1)\n",
    "        .tolist()\n",
    "    )\n",
    "    top_text = f\"Top regiões {show_top_n}: \" + \"/\".join(top_features)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))  # Taller to leave space below\n",
    "    im = ax.imshow(heatmap, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, cax=cax, label='Importância (XAI)')\n",
    "\n",
    "    # Add top features below figure\n",
    "    fig.text(0.26, 0.15, top_text, ha='center', fontsize=15)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])  # Leave space for bottom text\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_face_colormap(test, avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image and XAI alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_uint8(m): return (np.clip(m, 0, 1)*255).round().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean landmarks of already detected face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mesh = 'Datasets\\\\DatasetFaces\\\\Landmarks'\n",
    "\n",
    "model = 'VGGFace'\n",
    "#path_xai = f'experiments\\\\{model}\\\\xai_masks'\n",
    "#path_mean_XAI = f'experiments\\\\{model}\\\\xai_masks\\\\mean_masks'\n",
    "#path_results = f'experiments\\\\{model}\\\\ensemble_10_results.pkl'\n",
    "\n",
    "\n",
    "path_xai = f'experiments\\\\{model}\\\\xai_masks_MCDP'\n",
    "path_mean_XAI = f'experiments\\\\{model}\\\\xai_masks_MCDP\\\\mean_masks'\n",
    "path_results = f'experiments\\\\{model}\\\\results_MCDP_50_0.3.pkl'\n",
    "\n",
    "MCDP=True\n",
    "\n",
    "with open(path_results, 'rb') as f:\n",
    "    daata = pickle.load(f)\n",
    "    daata.pop('embeddings', None)  # Remove embeddings if present\n",
    "    dataframe = pd.DataFrame(daata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = []\n",
    "for i in os.listdir(path_mesh):\n",
    "    with open(os.path.join(path_mesh,f'{i}'), 'rb') as f:\n",
    "        face_mesh = np.array(pickle.load(f))\n",
    "\n",
    "    faces.append(face_mesh)\n",
    "\n",
    "faces_np = np.array(faces)\n",
    "face_mesh_mean = faces_np.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_mean = np.array([face_mesh_mean[86], \n",
    "                           face_mesh_mean[52],\n",
    "                           face_mesh_mean[61],\n",
    "                           face_mesh_mean[88],\n",
    "                           face_mesh_mean[38]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterar para usar std no MCDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MCDP == True:\n",
    "    aux = \"_std\"\n",
    "else:\n",
    "    aux = ''\n",
    "\n",
    "for tipo, condition in {\n",
    "    'TP': (dataframe['labels'] == 1) & (dataframe['preds'] == 1),\n",
    "    'TN': (dataframe['labels'] == 0) & (dataframe['preds'] == 0),\n",
    "    'FP': (dataframe['labels'] == 0) & (dataframe['preds'] == 1),\n",
    "    'FN': (dataframe['labels'] == 1) & (dataframe['preds'] == 0)\n",
    "}.items():\n",
    "    \n",
    "    stack_img = []\n",
    "    stack_GC = []\n",
    "    stack_IG = []\n",
    "\n",
    "    new_df = dataframe[condition]\n",
    "\n",
    "    warped_imgs = []\n",
    "    warped_xai_GC = []\n",
    "    warped_xai_IG = []\n",
    "\n",
    "    for _, row in new_df.iterrows():\n",
    "        img_path = row['img_names']\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        gc_id = img_path.split('\\\\')[-1].replace('.jpg', f'_GC{aux}.pkl')\n",
    "        ig_id = gc_id.replace('GC', 'IG')\n",
    "\n",
    "        with open(os.path.join(path_xai, gc_id), 'rb') as f:\n",
    "            mask_GC  = pickle.load(f)\n",
    "\n",
    "        with open(os.path.join(path_xai, ig_id), 'rb') as f:\n",
    "            mask_IG  = pickle.load(f)\n",
    "            \n",
    "        mask_GC = cv2.resize(mask_GC, (512,512))\n",
    "        mask_IG = cv2.resize(mask_IG, (512,512))\n",
    "                    \n",
    "        mesh_id = gc_id.replace(f'_GC{aux}.pkl', '.pkl')\n",
    "        with open(os.path.join(path_mesh, mesh_id), 'rb') as f:\n",
    "            face_mesh = np.array(pickle.load(f))\n",
    "        \n",
    "        if face_mesh is not None:\n",
    "            \n",
    "            landmarks =  np.array([face_mesh[86], \n",
    "                                    face_mesh[52],\n",
    "                                    face_mesh[61],\n",
    "                                    face_mesh[88],\n",
    "                                    face_mesh[38]])\n",
    "    \n",
    "            # first align image\n",
    "            transform_rigid = AffineTransform()\n",
    "            transform_rigid.estimate(src=landmarks_mean, dst=landmarks)\n",
    "            result = warp(img, transform_rigid) * 255\n",
    "            result_mask_GC = warp(mask_GC, transform_rigid)*255\n",
    "            result_mask_IG = warp(mask_IG, transform_rigid)*255\n",
    "\n",
    "            warped_imgs.append(result.astype(np.uint8))\n",
    "            warped_xai_GC.append(result_mask_GC.astype(np.uint8))\n",
    "            warped_xai_IG.append(result_mask_IG.astype(np.uint8))\n",
    "                                \n",
    "    mean_img = np.mean(np.array(warped_imgs), axis=0)/255\n",
    "\n",
    "    # Compute standard deviation and normalize it\n",
    "    #std_img = np.std(np.array(warped_imgs), axis=0) / 255\n",
    "    #std_img_norm = (std_img - std_img.min()) / (std_img.max() - std_img.min() + 1e-8)  # avoid division by 0\n",
    "\n",
    "    # Create red heatmap where R = std, G=B=0\n",
    "    #red_heatmap = np.zeros_like(mean_img)\n",
    "    #red_heatmap[..., 0] = std_img_norm[..., 0]  # only red channel\n",
    "\n",
    "    # Blend mean image with red std map\n",
    "    #overlay = (mean_img * 0.7 + red_heatmap * 0.3)\n",
    "\n",
    "    mean_xai_GC = np.mean(np.array(warped_xai_GC), axis=0)\n",
    "    mean_xai_IG = np.mean(np.array(warped_xai_IG), axis=0)\n",
    "\n",
    "    result_cam_GC, alpha_channel_cam_GC = attribution_mask_processing(mean_xai_GC)\n",
    "    result_cam_IG, alpha_channel_cam_IG = attribution_mask_processing(mean_xai_IG)\n",
    "\n",
    "    save_name = \"MEAN_GC_\" + tipo + aux + '.pkl'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result_cam_GC, f)\n",
    "\n",
    "    save_name = \"MEAN_IG_\" + tipo + aux + '.pkl'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result_cam_IG, f)\n",
    "\n",
    "    test_gc = np.expand_dims(((result_cam_GC * alpha_channel_cam_GC) > 0).astype('int'),-1)\n",
    "    test_ig = np.expand_dims(((result_cam_IG * alpha_channel_cam_IG) > 0).astype('int'),-1)\n",
    "\n",
    "    # Define the plot colors\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\",\"yellow\",\"red\"])\n",
    "\n",
    "    # Plot and save\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mean_img)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_name = tipo + '.png'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(mean_img)\n",
    "    plt.imshow(result_cam_GC, cmap=cmap, alpha=alpha_channel_cam_GC)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_name = tipo + '_GC' + aux + '.png'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(mean_img)\n",
    "    plt.imshow(result_cam_IG, cmap=cmap, alpha=alpha_channel_cam_IG)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_name = tipo + '_IG' + aux + '.png'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "classes = ['TP', 'TN', 'FP', 'FN']\n",
    "rows = ['', f'_GC{aux}', f'_IG{aux}']  # row suffixes\n",
    "\n",
    "# Load, resize, and prepare\n",
    "images = []\n",
    "for suffix in rows:\n",
    "    row_imgs = []\n",
    "    for c in classes:\n",
    "        fname = f\"{c}{suffix}.png\"\n",
    "        fpath = os.path.join(path_mean_XAI, fname)\n",
    "        img = cv2.imread(fpath)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Could not load {fpath}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)  # resize\n",
    "        row_imgs.append(img)\n",
    "    row_stack = np.hstack(row_imgs)   # stack row horizontally\n",
    "    images.append(row_stack)\n",
    "\n",
    "# Stack rows vertically\n",
    "final_img = np.vstack(images)\n",
    "\n",
    "# Save final panel\n",
    "save_path = os.path.join(path_mean_XAI, f\"merged_panel{aux}.png\")\n",
    "cv2.imwrite(save_path, cv2.cvtColor(final_img, cv2.COLOR_RGB2BGR))\n",
    "print(f\"Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_img = []\n",
    "stack_GC = []\n",
    "stack_IG = []\n",
    "name = 'Pain'\n",
    "\n",
    "for tipo in ['Pain', 'No Pain']:\n",
    "\n",
    "    if tipo == 'No Pain':\n",
    "        name = 'No Pain'\n",
    "        stack_img = []\n",
    "        stack_GC = []\n",
    "        stack_IG = []\n",
    "\n",
    "    if tipo == 'Pain':\n",
    "        new_df = dataframe[(dataframe['preds'] == 1)]\n",
    "    elif tipo == 'No Pain':\n",
    "        new_df = dataframe[(dataframe['preds'] == 0)]\n",
    "\n",
    "    scores = []\n",
    "\n",
    "\n",
    "    warped_imgs = []\n",
    "    warped_xai_GC = []\n",
    "    warped_xai_IG = []\n",
    "\n",
    "    for _, row in new_df.iterrows():\n",
    "        img_path = row['img_names']\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        gc_id = img_path.split('\\\\')[-1].replace('.jpg', '_GC.pkl')\n",
    "        ig_id = gc_id.replace('GC', 'IG')\n",
    "\n",
    "        with open(os.path.join(path_xai, gc_id), 'rb') as f:\n",
    "            mask_GC  = pickle.load(f)\n",
    "\n",
    "        with open(os.path.join(path_xai, ig_id), 'rb') as f:\n",
    "            mask_IG  = pickle.load(f)\n",
    "\n",
    "        mask_GC = cv2.resize(mask_GC, (512,512))\n",
    "        mask_IG = cv2.resize(mask_IG, (512,512))\n",
    "                    \n",
    "        mesh_id = gc_id.replace('_GC.pkl', '.pkl')\n",
    "        with open(os.path.join(path_mesh, mesh_id), 'rb') as f:\n",
    "            face_mesh = np.array(pickle.load(f))\n",
    "        \n",
    "        if face_mesh is not None:\n",
    "            \n",
    "            landmarks =  np.array([face_mesh[86], \n",
    "                                    face_mesh[52],\n",
    "                                    face_mesh[61],\n",
    "                                    face_mesh[88],\n",
    "                                    face_mesh[38]])\n",
    "    \n",
    "            # first align image\n",
    "            transform_rigid = AffineTransform()\n",
    "            transform_rigid.estimate(src=landmarks_mean, dst=landmarks)\n",
    "            result = warp(img, transform_rigid) * 255\n",
    "            result_mask_GC = warp(mask_GC, transform_rigid)*255\n",
    "            result_mask_IG = warp(mask_IG, transform_rigid)*255\n",
    "\n",
    "            warped_imgs.append(result.astype(np.uint8))\n",
    "            warped_xai_GC.append(result_mask_GC.astype(np.uint8))\n",
    "            warped_xai_IG.append(result_mask_IG.astype(np.uint8))\n",
    "                                \n",
    "    mean_img = np.mean(np.array(warped_imgs), axis=0)/255\n",
    "    mean_xai_GC = np.mean(np.array(warped_xai_GC), axis=0)\n",
    "    mean_xai_IG = np.mean(np.array(warped_xai_IG), axis=0)\n",
    "\n",
    "    result_cam_GC, alpha_channel_cam_GC = attribution_mask_processing(mean_xai_GC)\n",
    "    result_cam_IG, alpha_channel_cam_IG = attribution_mask_processing(mean_xai_IG)\n",
    "\n",
    "    save_name = \"MEAN_GC_\" + tipo + '.pkl'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result_cam_GC, f)\n",
    "\n",
    "    save_name = \"MEAN_IG_\" + tipo + '.pkl'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result_cam_IG, f)\n",
    "\n",
    "    test_gc = np.expand_dims(((result_cam_GC * alpha_channel_cam_GC) > 0).astype('int'),-1)\n",
    "    test_ig = np.expand_dims(((result_cam_IG * alpha_channel_cam_IG) > 0).astype('int'),-1)\n",
    "\n",
    "    # Define the plot colors\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\",\"yellow\",\"red\"])\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(mean_img)\n",
    "    plt.imshow(result_cam_GC, cmap=cmap, alpha=alpha_channel_cam_GC)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_name = tipo + '_GC' + '.png'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(mean_img)\n",
    "    plt.imshow(result_cam_IG, cmap=cmap, alpha=alpha_channel_cam_IG)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_name = tipo + '_IG' + '.png'\n",
    "    save_path = os.path.join(path_mean_XAI, save_name)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.1 # Step for probabilities range\n",
    "\n",
    "stack_img = []\n",
    "stack_GC = []\n",
    "stack_IG = []\n",
    "name = 'TP_TN'\n",
    "\n",
    "for tipo in ['TN', 'TP', 'FN', 'FP']:\n",
    "\n",
    "    if tipo == 'FN':\n",
    "        name = 'FP_FN'\n",
    "        stack_img = []\n",
    "        stack_GC = []\n",
    "        stack_IG = []\n",
    "\n",
    "    if tipo == 'TP':\n",
    "        new_df = dataframe[(dataframe['labels'] == dataframe['preds']) & (dataframe['labels'] == 1)]\n",
    "        confs = np.arange(0.5, 1.01, step).round(1)\n",
    "    elif tipo == 'TN':\n",
    "        new_df = dataframe[(dataframe['labels'] == dataframe['preds']) & (dataframe['labels'] == 0)]\n",
    "        confs = np.arange(0.0, 0.51, step).round(1)\n",
    "    elif tipo == 'FN':\n",
    "        new_df = dataframe[(dataframe['labels'] != dataframe['preds']) & (dataframe['labels'] == 1)]\n",
    "        confs = np.arange(0.0, 0.51, step).round(1)\n",
    "    elif tipo == 'FP':\n",
    "        new_df = dataframe[(dataframe['labels'] != dataframe['preds']) & (dataframe['labels'] == 0)]\n",
    "        confs = np.arange(0.5, 1.01, step).round(1)\n",
    "\n",
    "\n",
    "    scores = []\n",
    "    for c in range(len(confs) - 1):\n",
    "        conf_df = new_df[(new_df['probs'] >= confs[c]) & (new_df['probs'] < confs[c+1])]\n",
    "\n",
    "        if len(conf_df) > 0:\n",
    "\n",
    "            warped_imgs = []\n",
    "            warped_xai_GC = []\n",
    "            warped_xai_IG = []\n",
    "\n",
    "            for _, row in conf_df.iterrows():\n",
    "                img_path = row['img_names']\n",
    "\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                 \n",
    "                gc_id = img_path.split('\\\\')[-1].replace('.jpg', '_GC.npz')\n",
    "                ig_id = gc_id.replace('GC', 'IG')\n",
    "    \n",
    "                \n",
    "                mask_GC  = np.load(os.path.join(path_xai, gc_id))['mask'] / 255\n",
    "\n",
    "                \n",
    "                mask_IG  = np.load(os.path.join(path_xai, ig_id))['mask'] / 255\n",
    "\n",
    "                mask_GC = cv2.resize(mask_GC, (512,512))\n",
    "                mask_IG = cv2.resize(mask_IG, (512,512))\n",
    "                          \n",
    "                mesh_id = gc_id.replace('_GC.npz', '.pkl')\n",
    "                with open(os.path.join(path_mesh, mesh_id), 'rb') as f:\n",
    "                    face_mesh = np.array(pickle.load(f))\n",
    "               \n",
    "                if face_mesh is not None:\n",
    "                   \n",
    "                    landmarks =  np.array([face_mesh[86], \n",
    "                                            face_mesh[52],\n",
    "                                            face_mesh[61],\n",
    "                                            face_mesh[88],\n",
    "                                            face_mesh[38]])\n",
    "            \n",
    "                    # first align image\n",
    "                    transform_rigid = AffineTransform()\n",
    "                    transform_rigid.estimate(src=landmarks_mean, dst=landmarks)\n",
    "                    result = warp(img, transform_rigid) * 255\n",
    "                    result_mask_GC = warp(mask_GC, transform_rigid)*255\n",
    "                    result_mask_IG = warp(mask_IG, transform_rigid)*255\n",
    "\n",
    "                    warped_imgs.append(result.astype(np.uint8))\n",
    "                    warped_xai_GC.append(result_mask_GC.astype(np.uint8))\n",
    "                    warped_xai_IG.append(result_mask_IG.astype(np.uint8))\n",
    "                                        \n",
    "            mean_img = np.mean(np.array(warped_imgs), axis=0)/255\n",
    "            mean_xai_GC = np.mean(np.array(warped_xai_GC), axis=0)\n",
    "            mean_xai_IG = np.mean(np.array(warped_xai_IG), axis=0)\n",
    "\n",
    "            result_cam_GC, alpha_channel_cam_GC = attribution_mask_processing(mean_xai_GC)\n",
    "            result_cam_IG, alpha_channel_cam_IG = attribution_mask_processing(mean_xai_IG)\n",
    "\n",
    "            save_name = \"MEAN_GC_\" + tipo + \"_\" + str(confs[c]) + \"_\" + str(confs[c+1]) + '.npz'\n",
    "            save_path = os.path.join(path_mean_XAI, save_name)\n",
    "            result_cam_GC = to_uint8(result_cam_GC)\n",
    "            np.savez_compressed(save_path, mask=result_cam_GC)\n",
    "            \n",
    "\n",
    "            save_name = \"MEAN_IG_\" + tipo + \"_\" + str(confs[c]) + \"_\" + str(confs[c+1]) + '.npz'\n",
    "            save_path = os.path.join(path_mean_XAI, save_name)\n",
    "            result_cam_IG = to_uint8(result_cam_IG)\n",
    "            np.savez_compressed(save_path, mask=result_cam_IG)\n",
    "            \n",
    "\n",
    "            test_gc = np.expand_dims(((result_cam_GC * alpha_channel_cam_GC) > 0).astype('int'),-1)\n",
    "            test_ig = np.expand_dims(((result_cam_IG * alpha_channel_cam_IG) > 0).astype('int'),-1)\n",
    "\n",
    "            # Define the plot colors\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\",\"yellow\",\"red\"])\n",
    "\n",
    "            plt.figure(figsize=(10,10))\n",
    "\n",
    "            plt.subplot(331)\n",
    "            plt.imshow(mean_img)\n",
    "            plt.title('Avg')\n",
    "            plt.ylabel('GC')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.subplot(332)\n",
    "            plt.imshow(mean_img)\n",
    "            plt.imshow(result_cam_GC, cmap=cmap, alpha=alpha_channel_cam_GC)\n",
    "            plt.title('Avg XAI')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(333)\n",
    "            plt.imshow(mean_img * test_gc)\n",
    "            plt.title('Face Regions')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(334)\n",
    "            plt.imshow(mean_img)\n",
    "            plt.ylabel('IG')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.subplot(335)\n",
    "            plt.imshow(mean_img)\n",
    "            plt.imshow(result_cam_IG, cmap=cmap, alpha=alpha_channel_cam_IG)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(336)\n",
    "            plt.imshow(mean_img * test_ig)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            save_name = tipo + \"_\" + str(confs[c]) + \"_\" + str(confs[c+1]) + '.png'\n",
    "            save_path = os.path.join(path_mean_XAI, save_name)\n",
    "\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight',pad_inches=0)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create stacked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_img = []\n",
    "stack_GC = []\n",
    "stack_IG = []\n",
    "name = 'TP_TN'\n",
    "\n",
    "for tipo in ['TN', 'TP', 'FN', 'FP']:\n",
    "    if tipo == 'TP':\n",
    "        confs = np.arange(0.5, 1.01, step).round(1)\n",
    "    elif tipo == 'TN':\n",
    "        confs = np.arange(0.0, 0.51, step).round(1)\n",
    "    elif tipo == 'FN':\n",
    "        confs = np.arange(0.0, 0.51, step).round(1)\n",
    "    elif tipo == 'FP':\n",
    "        confs = np.arange(0.5, 1.01, step).round(1)\n",
    "\n",
    "    if tipo == 'FN':\n",
    "        name = 'FP_FN'\n",
    "        stack_img = []\n",
    "        stack_GC = []\n",
    "        stack_IG = []\n",
    "\n",
    "    for c in range(len(confs) - 1):\n",
    "        p = os.path.join(path_mean_XAI, tipo+\"_\"+str(confs[c])+\"_\"+str(confs[c+1])+\".png\")\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mean_img = img[81:977, 89:985]\n",
    "            GC = img[81:977, 1048:1944]\n",
    "            IG = img[1047:1944, 1048:1944]\n",
    "            \n",
    "            stack_img.append(mean_img)\n",
    "            stack_GC.append(GC)\n",
    "            stack_IG.append(IG)\n",
    "\n",
    "        except:\n",
    "            stack_img.append(np.zeros((896,896,3), dtype='float32'))\n",
    "            stack_GC.append(np.zeros((896,896,3), dtype='float32'))\n",
    "            stack_IG.append(np.zeros((896,896,3), dtype='float32'))\n",
    "\n",
    "    stack_img_x = np.hstack(stack_img)\n",
    "    #stack_GC_x = np.hstack(stack_GC)\n",
    "    #stack_IG_x = np.hstack(stack_IG)\n",
    "\n",
    "    #stack = np.vstack((stack_img_x, stack_GC_x, stack_IG_x))\n",
    "    cv2.imwrite(os.path.join(path_mean_XAI,f'{name}_all.png'), cv2.cvtColor(stack_img_x, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import AffineTransform, warp\n",
    "\n",
    "path_mesh = 'Datasets\\DatasetFaces\\Landmarks'\n",
    "\n",
    "faces = []\n",
    "for i in os.listdir(path_mesh):\n",
    "    with open(os.path.join(path_mesh,f'{i}'), 'rb') as f:\n",
    "        face_mesh = np.array(pickle.load(f))\n",
    "\n",
    "    faces.append(face_mesh)\n",
    "\n",
    "faces_np = np.array(faces)\n",
    "face_mesh_mean = faces_np.mean(axis=0)\n",
    "\n",
    "landmarks_mean = np.array([face_mesh_mean[86], \n",
    "                           face_mesh_mean[52],\n",
    "                           face_mesh_mean[61],\n",
    "                           face_mesh_mean[88],\n",
    "                           face_mesh_mean[38]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xai = os.path.join(path_experiments, 'xai_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'predictive_entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_entropy(p, eps=1e-8):\n",
    "    p = np.clip(p, eps, 1 - eps)  # avoid log(0)\n",
    "    return -p * np.log(p) - (1 - p) * np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['stds'] = np.array(dataframe['probs_uq'].tolist()).std(axis=1)\n",
    "dataframe['predictive_entropy'] = binary_entropy(np.mean(dataframe['probs_uq'].tolist(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['binned'] = pd.cut(dataframe[mode], bins=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_correct_pain = dataframe[(dataframe['labels'] == dataframe['preds']) & (dataframe['preds'] == 1)]\n",
    "dataframe_correct_no_pain = dataframe[(dataframe['labels'] == dataframe['preds']) & (dataframe['preds'] == 0)]\n",
    "\n",
    "dataframe_incorrect_pain = dataframe[(dataframe['labels'] != dataframe['preds']) & (dataframe['preds'] == 1)]\n",
    "dataframe_incorrect_no_pain = dataframe[(dataframe['labels'] != dataframe['preds']) & (dataframe['preds'] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"green\", \"yellow\", \"red\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_stack(daata, inverse=False):\n",
    "    stacked_imgs = []\n",
    "    stacked_GCs = []\n",
    "    stacked_IGs = []\n",
    "    stacked_alpha_GC = []\n",
    "    stacked_alpha_IG = []\n",
    "\n",
    "    for bin_range, group_3 in daata.groupby('binned'):\n",
    "        print(f\"Bin: {bin_range}\")\n",
    "        print(len(group_3))\n",
    "\n",
    "        if len(group_3) == 0:\n",
    "            stacked_imgs.append(np.zeros((512,512,3)))\n",
    "            stacked_GCs.append(np.zeros((512,512)))\n",
    "            stacked_IGs.append(np.zeros((512,512)))\n",
    "            stacked_alpha_GC.append(np.zeros((512,512)))\n",
    "            stacked_alpha_IG.append(np.zeros((512,512)))\n",
    "            print(\"No images in this group.\")\n",
    "            continue\n",
    "\n",
    "        warped_imgs = []\n",
    "        warped_GCs = []\n",
    "        warped_IGs = []\n",
    "\n",
    "        for path_img in group_3['img_names']:\n",
    "            img = cv2.imread(path_img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            with open(os.path.join(path_mesh, path_img.split(\"\\\\\")[-1].split(\".\")[0]+\".pkl\"), 'rb') as f:\n",
    "                face_mesh = np.array(pickle.load(f))\n",
    "\n",
    "            with open(os.path.join(path_xai, path_img.split(\"\\\\\")[-1].split(\".\")[0]+\"_GC.pkl\"), 'rb') as f:\n",
    "                GC_mask = np.array(pickle.load(f))\n",
    "\n",
    "            if GC_mask.mean() == 0:\n",
    "                GC_mask = np.zeros((512,512))\n",
    "\n",
    "            with open(os.path.join(path_xai, path_img.split(\"\\\\\")[-1].split(\".\")[0]+\"_IG.pkl\"), 'rb') as f:\n",
    "                IG_mask = np.array(pickle.load(f))\n",
    "\n",
    "            if IG_mask.mean() == 0:\n",
    "                IG_mask = np.zeros((512,512))\n",
    "\n",
    "            GC_mask = cv2.resize(GC_mask, (512,512))\n",
    "            IG_mask = cv2.resize(IG_mask, (512,512))\n",
    "\n",
    "            landmarks =  np.array([face_mesh[86], \n",
    "                                    face_mesh[52],\n",
    "                                    face_mesh[61],\n",
    "                                    face_mesh[88],\n",
    "                                    face_mesh[38]])\n",
    "            \n",
    "            transform_rigid = AffineTransform()\n",
    "            transform_rigid.estimate(src=landmarks_mean, dst=landmarks)\n",
    "            result = warp(img, transform_rigid) * 255\n",
    "            result_GC = warp(GC_mask, transform_rigid) * 255\n",
    "            result_IG = warp(IG_mask, transform_rigid) * 255\n",
    "\n",
    "            warped_imgs.append(result.astype(np.uint8))\n",
    "            warped_GCs.append(result_GC.astype(np.uint8))\n",
    "            warped_IGs.append(result_IG.astype(np.uint8))\n",
    "\n",
    "        mean_img = np.mean(np.array(warped_imgs), axis=0)/255\n",
    "        mean_xai_GC = np.mean(np.array(warped_GCs), axis=0)\n",
    "        mean_xai_IG = np.mean(np.array(warped_IGs), axis=0)\n",
    "\n",
    "        result_cam_GC, alpha_channel_cam_GC = attribution_mask_processing(mean_xai_GC)\n",
    "        result_cam_IG, alpha_channel_cam_IG = attribution_mask_processing(mean_xai_IG)\n",
    "        \n",
    "        stacked_imgs.append(mean_img)\n",
    "        stacked_GCs.append(result_cam_GC)\n",
    "        stacked_IGs.append(result_cam_IG)\n",
    "        stacked_alpha_GC.append(alpha_channel_cam_GC)\n",
    "        stacked_alpha_IG.append(alpha_channel_cam_IG)\n",
    "\n",
    "    if inverse:\n",
    "        stacked_imgs = stacked_imgs[::-1]\n",
    "        stacked_GCs = stacked_GCs[::-1]\n",
    "        stacked_IGs = stacked_IGs[::-1]\n",
    "        stacked_alpha_GC = stacked_alpha_GC[::-1]\n",
    "        stacked_alpha_IG = stacked_alpha_IG[::-1]\n",
    "        \n",
    "    test_img = np.hstack(stacked_imgs) * 255\n",
    "    test_GC = np.hstack(stacked_GCs) * 255\n",
    "    test_IG = np.hstack(stacked_IGs) * 255\n",
    "    test_alpha_GC = np.hstack(stacked_alpha_GC)\n",
    "    test_alpha_IG = np.hstack(stacked_alpha_IG)\n",
    "\n",
    "    return test_img, test_GC, test_IG, test_alpha_GC, test_alpha_IG\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pain_img, correct_pain_GC, correct_pain_IG, correct_pain_alpha_GC, correct_pain_alpha_IG = generate_stack(dataframe_correct_pain, inverse=True)\n",
    "correct_no_pain_img, correct_no_pain_GC, correct_no_pain_IG, correct_no_pain_alpha_GC, correct_no_pain_alpha_IG = generate_stack(dataframe_correct_no_pain, inverse=False)\n",
    "incorrect_pain_img, incorrect_pain_GC, incorrect_pain_IG, incorrect_pain_alpha_GC, incorrect_pain_alpha_IG = generate_stack(dataframe_incorrect_pain, inverse=True)\n",
    "incorrect_no_pain_img, incorrect_no_pain_GC, incorrect_no_pain_IG, incorrect_no_pain_alpha_GC, incorrect_no_pain_alpha_IG = generate_stack(dataframe_incorrect_no_pain, inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_imgs_corrects = np.hstack([correct_no_pain_img, correct_pain_img])\n",
    "stack_GCs_corrects = np.hstack([correct_no_pain_GC, correct_pain_GC])\n",
    "stack_IGs_corrects = np.hstack([correct_no_pain_IG, correct_pain_IG])\n",
    "stack_GC_alpha_corrects = np.hstack([correct_no_pain_alpha_GC, correct_pain_alpha_GC])\n",
    "stack_IG_alpha_corrects = np.hstack([correct_no_pain_alpha_IG, correct_pain_alpha_IG])\n",
    "\n",
    "\n",
    "plt.imshow(stack_imgs_corrects.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.savefig('corrects.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.imshow(stack_imgs_corrects.astype(np.uint8))\n",
    "plt.imshow(stack_GCs_corrects.astype(np.uint8), alpha=stack_GC_alpha_corrects.astype(np.float32), cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig('corrects_GC.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.imshow(stack_imgs_corrects.astype(np.uint8))\n",
    "plt.imshow(stack_IGs_corrects.astype(np.uint8), alpha=stack_IG_alpha_corrects.astype(np.float32), cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig('corrects_IG.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_1 = cv2.imread('corrects.png')\n",
    "stack_2 = cv2.imread('corrects_GC.png')\n",
    "stack_3 = cv2.imread('corrects_IG.png')\n",
    "\n",
    "cv2.imwrite('corrects_all.png', np.vstack([stack_1, stack_2, stack_3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_imgs_incorrects = np.hstack([incorrect_no_pain_img, incorrect_pain_img])\n",
    "stack_GCs_incorrects = np.hstack([incorrect_no_pain_GC, incorrect_pain_GC])\n",
    "stack_IGs_incorrects = np.hstack([incorrect_no_pain_IG, incorrect_pain_IG])\n",
    "stack_GC_alpha_incorrects = np.hstack([incorrect_no_pain_alpha_GC, incorrect_pain_alpha_GC])\n",
    "stack_IG_alpha_incorrects = np.hstack([incorrect_no_pain_alpha_IG, incorrect_pain_alpha_IG])\n",
    "\n",
    "\n",
    "plt.imshow(stack_imgs_incorrects.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.savefig('incorrects.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.imshow(stack_imgs_incorrects.astype(np.uint8))\n",
    "plt.imshow(stack_GCs_incorrects.astype(np.uint8), alpha=stack_GC_alpha_incorrects.astype(np.float32), cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig('incorrects_GC.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.imshow(stack_imgs_incorrects.astype(np.uint8))\n",
    "plt.imshow(stack_IGs_incorrects.astype(np.uint8), alpha=stack_IG_alpha_incorrects.astype(np.float32), cmap=cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig('incorrects_IG.png', dpi=300, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_1 = cv2.imread('incorrects.png')\n",
    "stack_2 = cv2.imread('incorrects_GC.png')\n",
    "stack_3 = cv2.imread('incorrects_IG.png')\n",
    "\n",
    "cv2.imwrite('incorrects_all.png', np.vstack([stack_1, stack_2, stack_3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Difference between Correct and Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(mask, post=True):\n",
    "\n",
    "    if post:\n",
    "        mask, alpha_mask = attribution_mask_processing(mask)\n",
    "        \n",
    "        mask[np.where(alpha_mask == 1)] = 1\n",
    "        mask[np.where(alpha_mask == 0)] = 0\n",
    "\n",
    "    else:\n",
    "        mask[np.where(mask > 0)] = 1\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = 'VGGNB'\n",
    "\n",
    "device = 'cuda'\n",
    "folder = 'UNIFESP+iCOPE'\n",
    "\n",
    "mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_experiments1 = f'experiments\\\\{folder}\\\\{model1}'\n",
    "path_masks1 = os.path.join(path_experiments1, 'xai_masks')\n",
    "path_TP1 = os.path.join(path_experiments1, 'xai_masks', 'TP')\n",
    "path_TN1 = os.path.join(path_experiments1, 'xai_masks', 'TN')\n",
    "path_FP1 = os.path.join(path_experiments1, 'xai_masks', 'FP')\n",
    "path_FN1 = os.path.join(path_experiments1, 'xai_masks', 'FN')\n",
    "\n",
    "all_path1 = []\n",
    "all_path1.extend(os.listdir(path_TP1))\n",
    "all_path1.extend(os.listdir(path_TN1))\n",
    "all_path1.extend(os.listdir(path_FP1))\n",
    "all_path1.extend(os.listdir(path_FN1))\n",
    "\n",
    "all_path1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xai in [\"GC\", \"IG\"]:\n",
    "\n",
    "    test = []\n",
    "\n",
    "    for model2 in [\"_LS_01\", \"_LS_03\", \"_LS_05\", \"_SIGMOID\", \"_STEP\", \"_LINEAR\"]:\n",
    "\n",
    "        path_experiments2 = f'experiments\\\\{folder}\\\\{model1}{model2}'\n",
    "        path_masks2 = os.path.join(path_experiments2, 'xai_masks')\n",
    "        path_TP2 = os.path.join(path_experiments2, 'xai_masks', 'TP')\n",
    "        path_TN2 = os.path.join(path_experiments2, 'xai_masks', 'TN')\n",
    "        path_FP2 = os.path.join(path_experiments2, 'xai_masks', 'FP')\n",
    "        path_FN2 = os.path.join(path_experiments2, 'xai_masks', 'FN')\n",
    "\n",
    "        all_path2 = []\n",
    "        all_path2.extend(os.listdir(path_TP2))\n",
    "        all_path2.extend(os.listdir(path_TN2))\n",
    "        all_path2.extend(os.listdir(path_FP2))\n",
    "        all_path2.extend(os.listdir(path_FN2))\n",
    "\n",
    "        all_path2.sort()\n",
    "\n",
    "        mse = []\n",
    "\n",
    "        for path1, path2 in zip(all_path1, all_path2):\n",
    "            if path1.endswith('.pkl') and path2.endswith('.pkl'): \n",
    "                \n",
    "                split1 = path1.split(\"_\")\n",
    "                split2 = path2.split(\"_\")\n",
    "\n",
    "                if split1[0] == split2[0] and split1[4] == xai and split2[4] == xai:\n",
    "\n",
    "                    if split1[5] == \"1\" and split1[6] == \"1\":\n",
    "                        path = path_TP1\n",
    "                    elif split1[5] == \"0\" and split1[6] == \"0\":\n",
    "                        path = path_TN1\n",
    "                    elif split1[5] == \"1\" and split1[6] == \"0\":\n",
    "                        path = path_FN1\n",
    "                    elif split1[5] == \"0\" and split1[6] == \"1\":\n",
    "                        path = path_FP1\n",
    "\n",
    "                    with open(os.path.join(path, path1), 'rb') as f:\n",
    "                        mask_1 = pickle.load(f)\n",
    "\n",
    "                    if split2[5] == \"1\" and split2[6] == \"1\":\n",
    "                        path = path_TP2\n",
    "                    elif split2[5] == \"0\" and split2[6] == \"0\":\n",
    "                        path = path_TN2\n",
    "                    elif split2[5] == \"1\" and split2[6] == \"0\":\n",
    "                        path = path_FN2\n",
    "                    elif split2[5] == \"0\" and split2[6] == \"1\":\n",
    "                        path = path_FP2\n",
    "\n",
    "                    with open(os.path.join(path, path2), 'rb') as f:\n",
    "                        mask_2 = pickle.load(f)\n",
    "\n",
    "                    if mask_1.mean() !=0 and mask_2.mean() !=0:\n",
    "\n",
    "                        mask_1 = processing(mask_1, mode)\n",
    "                        mask_2 = processing(mask_2, mode)\n",
    "\n",
    "                        #mse.append(overlap_schiller(mask_1, mask_2))\n",
    "                        mse.append(IoU(mask_1, mask_2))\n",
    "        \n",
    "        mse = np.array(mse)\n",
    "\n",
    "        print(f\"{model2} {xai}: {(mse.mean()):.4f} ± {mse.std():.4f}\")\n",
    "        test.append(mse)\n",
    "\n",
    "    # Create a box plot\n",
    "    plt.boxplot(test, labels=[\"LS_01\", \"LS_03\", \"LS_05\", \"SIGMOID\", \"STEP\", \"LINEAR\"])\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('Overlap')\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xai in [\"GC\", \"IG\"]:\n",
    "\n",
    "    print(xai)\n",
    "\n",
    "    for model2 in [\"\", \"_LS_01\", \"_LS_03\", \"_LS_05\", \"_SIGMOID\", \"_STEP\", \"_LINEAR\"]:\n",
    "\n",
    "        path_experiments = f'experiments\\\\{folder}\\\\{model1}{model2}'\n",
    "        path_masks = os.path.join(path_experiments, 'xai_masks')\n",
    "\n",
    "        conf_N = np.arange(0.0, 0.51, 0.1).round(1)\n",
    "        conf_P = np.arange(0.5, 1.01, 0.1).round(1)\n",
    "\n",
    "        s = ''\n",
    "\n",
    "        for confs, u in zip([conf_N, conf_P], [\"N\", \"P\"]):\n",
    "            mse = []\n",
    "\n",
    "            for c in range(len(confs)-1):\n",
    "                path_1 = os.path.join(path_masks, \"mean_masks\", f\"MEAN_{xai}_T{u}_{confs[c]}_{confs[c+1]}.pkl\")\n",
    "                path_2 = os.path.join(path_masks, \"mean_masks\", f\"MEAN_{xai}_F{u}_{confs[c]}_{confs[c+1]}.pkl\")\n",
    "\n",
    "                try:\n",
    "                    with open(path_1, 'rb') as f:\n",
    "                        mask_1 = pickle.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    mask_1 = np.zeros((512,512))\n",
    "\n",
    "                try:\n",
    "                    with open(path_2, 'rb') as f:\n",
    "                        mask_2 = pickle.load(f)\n",
    "                except FileNotFoundError:\n",
    "                    mask_2 = np.zeros((512,512))\n",
    "\n",
    "                if mask_1.mean() !=0 and mask_2.mean() != 0:\n",
    "\n",
    "                    mask_1 = processing(mask_1, post=True)\n",
    "                    mask_2 = processing(mask_2, post=True)\n",
    "\n",
    "    \n",
    "                    #diff = round(overlap_schiller(mask_1, mask_2), 4)\n",
    "                    diff = round(IoU(mask_1, mask_2), 4)\n",
    "\n",
    "\n",
    "                    #plt.figure()\n",
    "                    #plt.imshow(mask_1, cmap='Reds', alpha=0.5)\n",
    "                    #plt.imshow(mask_2, cmap='Blues', alpha=0.5)\n",
    "                    #plt.title(diff)\n",
    "                    #plt.show()\n",
    "\n",
    "                    s = s + ';' + str(diff).replace('.',',')\n",
    "                else:\n",
    "                    s = s + ';' + '-'\n",
    "\n",
    "            \n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doutorado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
